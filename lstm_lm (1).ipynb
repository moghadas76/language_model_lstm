{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm-lm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grWkyPzaYtwX"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4MH1L9L-owq",
        "outputId": "8895d454-4232-4cc4-8326-20ed8df410d1"
      },
      "source": [
        "!pip install hazm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hazm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/13/5a7074bc11d20dbbb46239349ac3f85f7edc148b4cf68e9b8c2f8263830c/hazm-0.7.0-py3-none-any.whl (316kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 12.7MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/0f/1c9b49bb49821b5856a64ea6fac8d96a619b9f291d1f06999ea98a32c89c/libwapiti-0.2.1.tar.gz (233kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 17.3MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/09/3b1755d528ad9156ee7243d52aa5cd2b809ef053a0f31b53d92853dd653a/nltk-3.3.0.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 26.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from libwapiti>=0.2.1; platform_system != \"Windows\"->hazm) (1.15.0)\n",
            "Building wheels for collected packages: libwapiti, nltk\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=153929 sha256=b3014767336ac1e69eddfbc63fabe4fcf2ce8ddc5beef94ad29a61f8c5dcad2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/15/54/4510dce8bb958b1cdd2c47425cbd1e1eecc0480ac9bb1fb9ab\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-cp37-none-any.whl size=1394486 sha256=55c3e638fdc21f0f246f3843e7aebe0a1f2a5ccd89d0221d5ad51ad0b361558b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ab/40/3bceea46922767e42986aef7606a600538ca80de6062dc266c\n",
            "Successfully built libwapiti nltk\n",
            "Installing collected packages: libwapiti, nltk, hazm\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsUfqNNdnmht",
        "outputId": "80a21f06-770d-47e5-e8e4-cc411efd7838"
      },
      "source": [
        "!pip install torchinfo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/d3/11f9901d75f4d105b2b1700c81f83579fd33c4cf0ec88bb7a165d96c7bb4/torchinfo-0.1.5-py3-none-any.whl\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-0.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tC-U8hG0gud"
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sc\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from __future__ import unicode_literals\n",
        "from hazm import *\n",
        "import json\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_sYEzTSqBPI",
        "outputId": "ec878daa-e841-495e-c1df-a8e33cd8fcbb"
      },
      "source": [
        "!apt install unrar"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:5.5.8-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXpngsb0oM3G",
        "outputId": "c6ebaaf2-ed36-4664-a357-f757f455869b"
      },
      "source": [
        "random.seed(1024)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwVz8XIwqmeZ",
        "outputId": "bc3d7e7f-224e-4f56-b5b3-efa8bc4ece11"
      },
      "source": [
        "!unrar e /content/drive/MyDrive/projects/language_model/News.rar"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/projects/language_model/News.rar\n",
            "\n",
            "Extracting  train.csv                                                    \b\b\b\b  5%\b\b\b\b 11%\b\b\b\b 16%\b\b\b\b 22%\b\b\b\b 27%\b\b\b\b 33%\b\b\b\b 38%\b\b\b\b 44%\b\b\b\b 49%\b\b\b\b 55%\b\b\b\b 61%\b\b\b\b 66%\b\b\b\b 72%\b\b\b\b 77%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  test.csv                                                     \b\b\b\b 89%\b\b\b\b 95%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Br2N2P4qm4y"
      },
      "source": [
        "train_data = pd.read_csv(\"./train.csv\",sep=\"\\t\", error_bad_lines= False , encoding= 'utf-8')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMrqSII0e7zO"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUuRpaJ4tVVy"
      },
      "source": [
        "ex = list(range(238, 264))\n",
        "ex.remove(243)\n",
        "excludes = list(range(45,52)) + list(range(53,58)) + list(range(59,73)) + list(range(74,87)) + list(range(88,97)) + list(range(98,102)) + [104, 136, 137, 142, 209 , 210, 214, 215, 216, 224, 225, 235] + list(range(218, 222)) + ex\n",
        "class Preprocessor:\n",
        "\n",
        "  def __init__(self, df, excludes=excludes):\n",
        "    self.train_data = df\n",
        "    self.train_data = self.train_data.dropna(subset=['category'])\n",
        "    self.train_data = self.train_data.loc[self.train_data['category']!='category']\n",
        "    self.excludes = excludes\n",
        "    self.clean()\n",
        "    self.count_chars()\n",
        "    self.tokens = self.tokenize()\n",
        "\n",
        "  def clean(self):\n",
        "    replaced = []\n",
        "    for sentence in self.train_data.text.astype(str):\n",
        "      replaced.append(re.sub(\"\\d+\",\"N\",sentence))\n",
        "    ws = []\n",
        "    # normalizer = Normalizer()\n",
        "    for a in replaced:\n",
        "      # st = normalizer.normalize(a)\n",
        "      w = [\"\\s\"] + [tk for tk in word_tokenize(a) if tk.isalpha()] + ['\\e']\n",
        "      ws.append(' '.join(w))\n",
        "    self.cleaned_list = ws\n",
        "\n",
        "  def count_chars(self):\n",
        "    word2index = {}\n",
        "    index2word = {}\n",
        "    total_words= sum([len(token) for sent in self.cleaned_list for token in sent])\n",
        "    for sent in self.cleaned_list:\n",
        "      for char in sorted(list(set(sent))):\n",
        "        if word2index.get(char) is None:\n",
        "            word2index[char] = len(word2index)\n",
        "    index2word = {v:k for k,v in word2index.items()}\n",
        "    uniques = len(index2word)\n",
        "    print(f\"\\nTotal characters = {total_words}\")\n",
        "    print(f\"\\nUnique characters = {uniques}\")\n",
        "    with open(\"w2i.txt\",\"w\") as file:\n",
        "      file.write(json.dumps(word2index,indent=4,ensure_ascii=False))\n",
        "    with open(\"i2w.txt\",\"w\") as file:\n",
        "      file.write(json.dumps(index2word,indent=4,ensure_ascii=False))\n",
        "    self.word2index = word2index\n",
        "    self.index2word = index2word\n",
        "\n",
        "\n",
        "  def tokenize(self):\n",
        "    tokens = []\n",
        "    for sent in self.cleaned_list:\n",
        "      for char in list(sent):\n",
        "        if(self.word2index[char] not in self.excludes):\n",
        "          tokens.append(self.word2index[char])\n",
        "    data = torch.tensor(tokens).to(device)\n",
        "    data = torch.unsqueeze(data, dim=1) \n",
        "    return data"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXlP0UPItV06",
        "outputId": "fd99e844-1d5f-402a-ba32-086de86b7497"
      },
      "source": [
        "pre = Preprocessor(train_data)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total characters = 146940000\n",
            "\n",
            "Unique characters = 277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpTXelhvtWR3",
        "outputId": "48fa85e6-7051-440b-a605-7f6b005d37b1"
      },
      "source": [
        "pre.cleaned_list[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\\\s به گزارش خبرنگار حوزه میراث و فرهنگی باشگاه خبرنگاران جوان محمد حسن خان اعتماد السلطنه به نقل از برخی منابع اسفراین چمن کالپوش چمن کالپوش بر اساس آنچه در اعتقادات اهالی منطقه مشهود است آخرین منزلگاه داریوش سوم است بنابراین باید دشت اسفراین را جولانگاه مقدونیان دانست این دشت از دستبرد و سم ستوران یونانی در امان بنا بر این گزارش شهر اسفراین امروزی در شمال غربی استان خراسان شمالی قرار این شهر دربرگیرنده بیش از N بقعه از بزرگان و امامزادگان است شایان ذکر است شهر فعلی اسفراین از N محله تشکیل شده و زیستگاه حیواناتی چون آهو گرگ گورکن خرگوش روباه گراز پلنگ کفتار و بز کوهی است منطقه ساری گل در شمال شرقی اسفراین قرار گفتنی است ابوعبدلله حمد بن احمد مقدسی در خصوص اسفراین اسفراین روستایی بزرگ و مرکز انگور خوب و کشتزار است جاده گرگان آن را به دو نیمه شهر آن به همین نام است آباد و گرانقدر است از نهری که از کوه در این روستا از آن نیست مردم آن اهل حدیثند خاطرنشان ابوعبدالله الحاکم مؤلف تاریخ نیشابور نیز اسفراین را شهری خوش آب و هوا ذکر است و قباد پادشاه ساسانی نام اسفراین را به علت داشتن آب و هوای خوب مهرجان است \\\\e',\n",
              " '\\\\s به گزارش حوزه موسیقی باشگاه خبرنگاران مهدی یغمایی جوان و خوش ذوق موسیقی پاپ به گفته خود یکی از نوادگان یغمای جندقی شاعر مرثیه سرای قرن N هجری است وی در سال N در آلبوم زیبا و دلنشین سلام آقا که به پیشگاه مقدس و سرور و سالار شهیدان و خاندان پاکشان تقدیم شد به همراه جمعی از ستارگان موسیقی پاپ به اجرای قطعات ماندگار و دلنشین پرداخت که به این بهانه به گفتگو با وی آقای یغمایی در ساخت قطعاتی که به پیشگاه مقدس امام حسین ع و خاندان پاک ایشان تقدیم چه عواملی باید وجود آقای یغمایی در ساخت قطعاتی که به پیشگاه مقدس امام حسین ع و خاندان پاک ایشان تقدیم چه عواملی باید وجود ساخت این قطعات مستلزم اعتقاد قلبی عمیق است در آلبوم سلام آقا من بدون هیچ قراردادی N قطعه را اجرا کردم و به طور کلی از عمق وجودم به اجرای این قطعات پرداختم در این مجموعه برای من انگیزه مالی به هیچ عنوان مطرح نبوده و وقتی این آلبوم مجوز گرفت سجده شکر کردم ساخت این قطعات مستلزم اعتقاد قلبی عمیق است در آلبوم سلام آقا من بدون هیچ قراردادی N قطعه را اجرا کردم و به طور کلی از عمق وجودم به اجرای این قطعات پرداختم در این مجموعه برای من انگیزه مالی به هیچ عنوان مطرح نبوده و وقتی این آلبوم مجوز گرفت سجده شکر کردم این گونه قطعات با مضمون عاشورایی چه حسی را در شما این گونه قطعات با مضمون عاشورایی چه حسی را در شما قطعاتی با مضمون حماسه عظیم کربلا خیلی فراتر از موسیقی پاپ است در N قطعه اجرایی من در سلام آقا N قطعه دارای نوستالوژی بسیار بود و دو قطعه دیگری که دوست عزیزم مهدی یراحی به آهنگسازی آن به فضای موسیقی پاپ بود در موسیقی پاپ به طور بحث تجارت مطرح است و آثار تولیدی به طور قطع از جنبه مادی نیز برخوردار است اما آثاری نظیر سلام آقا به رغم قرار گرفتن در زمره موسیقی پاپ از این مقوله به طور کامل مبرا هستند و برای من به شخصه هیچ انگیزه و جنبه مالی در تولید این اثر وجود نداشت و تنها بر مبنای یک اعتقاد عمیق درونی بود و یقینا تا آخرین نفس در زندگیم به اجرای این گونه آثار زیرا این موضوع برای من افتخار بزرگی است قطعاتی با مضمون حماسه عظیم کربلا خیلی فراتر از موسیقی پاپ است در N قطعه اجرایی من در سلام آقا N قطعه دارای نوستالوژی بسیار بود و دو قطعه دیگری که دوست عزیزم مهدی یراحی به آهنگسازی آن به فضای موسیقی پاپ بود در موسیقی پاپ به طور بحث تجارت مطرح است و آثار تولیدی به طور قطع از جنبه مادی نیز برخوردار است اما آثاری نظیر سلام آقا به رغم قرار گرفتن در زمره موسیقی پاپ از این مقوله به طور کامل مبرا هستند و برای من به شخصه هیچ انگیزه و جنبه مالی در تولید این اثر وجود نداشت و تنها بر مبنای یک اعتقاد عمیق درونی بود و یقینا تا آخرین نفس در زندگیم به اجرای این گونه آثار زیرا این موضوع برای من افتخار بزرگی است \\\\e',\n",
              " '\\\\s به گزارش حوزه تئاتر باشگاه خبرنگاران به نقل روابط عمومی مرکز هنرهای نمایشی حوزه هنری پژمان کاشفی کارگردان این اثر نمایشی اظهار کرد نمایش سیاریحون را حدود هشت سال پیش حمید ابراهیمی به صحنه که من نیز در آن پروژه همکاری داشتم از آنجا که این متن را خیلی دوست داشتم و اکنون زمان را برای اجرای دوباره آن مناسب دیدم تصمیم گرفتم این متن را امسال در بیست و دومین سراسری تئاتر ماه شرکت دهم که به لطف خدا اجرای این نمایش در جشنواره با استقبال مخاطبان و تماشاگران مواجه شد وی در مورد تغییرات ایجاد شده در اجرای سیاریحون نسبت به اجرای هشت سال پیش توضیح داد در این کار از حمید ابراهیمی عزیز بسیار استفاده و با اینکه او در این پروژه همراه ما نبود همچون یک استاد راهنما در روند تکمیل کار من موثر بود ولی با این حال تغییراتی را در اجرا و از متن ایجاد که گرچه حمید ابراهیمی به عنوان نویسنده چندان موافق آن نبود اما فکر با این تغییرات کار را مضاعف کنیم پژمان کاشفی در پایان اذعان کرد در مقام کارگردان از نمایشی که آماده بسیار راضی ام و امیدوارم تماشاگران نیز از تماشای آن لذت ببرند گفتنی است سیاریحون داستانی برگرفته از کتاب بزرگ علوی است که به مقاومت از همرزمان میرزا جنگلی در مقابل خان این نمایش با حضور در بیست و دومین سراسری تئاتر ماه توانست اول بازیگری زن و اول بخش موسیقی را از آن خود کند ابوالفضل ندا گلرنگی سپهر گودرزی مصطفی اکبری حمیدرضا طوبایی شقایق فتحی و جمال فؤادیان از جمله بازیگران این نمایش اند ضمن اینکه طراحی این اثر نیز بر علیرضا مهران بوده و ساخت موسیقی که به صورت زنده اجرا نیز از سوی سعید رضایت انجام انتهای \\\\e',\n",
              " '\\\\s به گزارش خبرنگار رادیو تلویزیون باشگاه مجموعه تلویزیونی مدرس به کارگردانی هوشنگ توکلی و تهیه کنندگی شنگله از شبکه یک سیما در سال N پخش شد این اثر که داستان زندگی سید مدرس را به تصویر به از زندگی این شهید بزرگوار از ورود به تا کاندیدا شدن ایشان در مجلس شورای اسلامی و درگیری با رضا شاه و کشته شدن به دستور رضا شاه پرداخت این سریال به دلیل بازی درخشان تحسین برانگیز خسرو شکیبایی در نقش مدرس در یادها شد خسرو شکیبایی بی شک یکی از ماندگار ترین را در این سریال به کشید از جمله وی در این سریال N را حتی بدون یک بار کات دادن کرد و با قدرت بیان فوق قدرت و استواری مدرس در برابر رضا شاه را خوبی به تصویر کشید تا کنون نقش شهید مدرس بازیگرانی چون زنده یاد هادی اسلامی در سریال تلویزیونی حق و حسین محجوب در اثر عمارت فرنگی ایفا که هم به خوبی از پس نقش برآیند هوشنگ توکلی سریال تلویزیونی مدرس در گفتگو با خبرنگار ما در خصوص ساخت این گفت اهالی هنر پس از انقلاب ساخت چنین آثاری بود وی افزود یکی از که تا کنون در مجلس حضور داشته شهید مدرس بود به همین دلیل ما در آن زمان این شخصیت پرداختیم و مدیر شبکه یک و مدیر گروه سریال آن زمان بر روی این بسیار حساس بودند توکلی عنوان کرد این اثر یکی پر مخاطب ترین تلویزیونی آن دوران بود که N درصد بیننده داشت این کارگردان در خصوص بازی یاد خسرو شکیبایی در نقش مدرس بیان کرد شکیبایی یکی بازیگران با سابقه و با تجربه بود و علاقه خاصی به داشت و برای نقش مدرس هم وقت و انرژی زیادی را صرف کرد وی ادامه داد شکیبایی این نقش به نام خودش ثبت کرد و پس از پیشنهاد این کار نقش را چشم بسته پذیرفت البته بازیگران این اثر جزء N بودند انتهای اس \\\\e',\n",
              " '\\\\s به گزارش خبرنگار تکیه فرهنگی باشگاه خبرنگاران جوان تصاویر مراسم عزاداری شب ششم محرم N هیئت مکتب الزهرا و هیئت ریحانة الحسین س هیئت عبدالله بن الحسن ع با مداحی محمدرضا طاهری حسین طاهری سید مجید بنی فاطمه و حیف طاهری را در این گزارش مشاهده کنید شب گذشته علوی وزیر اطلاعات محسن رضایی دبیر مجمع تشخیص مصلحت نظام سردار حسین رحیمی رئیس پلیس تهران بزرگ کوروش تهامی و علی هیئت مکتب الزهرا و هیئت ریحانة الحسین س حضور داشتند \\\\e']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sGXZSQumy5M",
        "outputId": "3f979ab1-a941-43fa-f881-b8474b273699"
      },
      "source": [
        "pre.tokens.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([145323109, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3VHmGfVRt4k",
        "outputId": "3f01fb9a-306c-499b-9eea-0a0f2002ed33"
      },
      "source": [
        "len(excludes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek1XWMtcYU4w"
      },
      "source": [
        "## Model section\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y3VQ9D56dVE"
      },
      "source": [
        "class LanguageModel(nn.Module):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, input_size, num_layers, output_size, hidden_size, dropout=0.25, bidirectional=False):\n",
        "    super(LanguageModel, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.num_layers = num_layers\n",
        "    self.output_size = output_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.dropout = dropout\n",
        "    self.bidirectional = bidirectional\n",
        "    self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, dropout=self.dropout, bidirectional=self.bidirectional, batch_first=True)\n",
        "    self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
        "  \n",
        "  def forward(self, input, hidden):\n",
        "    output, _hidden = self.lstm(input, hidden)\n",
        "    linear = self.linear(output.contiguous().view(output.size(0) * output.size(1), -1))\n",
        "    # print(linear.shape,\"*********\")\n",
        "    return linear, _hidden "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2aPtd5A3tSx"
      },
      "source": [
        "model = LanguageModel(1,2,277,512).to(device)\n",
        "# model = LanguageModel(1,2,277,512).to(device)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBT8GoQfdCj2"
      },
      "source": [
        "NUM_EPOCHS = 1\n",
        "BATCH_SIZE = 256\n",
        "SEQ_LENGTH = 30\n",
        "HIDDEN_SIZE = 512\n",
        "NUM_LAYERS = 2\n",
        "learning_rate = 0.002"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Agi1SLcp_5O",
        "outputId": "2e0257fb-b8cc-4079-b125-a634a08d90a9"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3298069"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJUmOkBx5QWt",
        "outputId": "aa6fd2cb-8ea4-4477-b432-e09d0cbec177"
      },
      "source": [
        "torch.unsqueeze(pre.tokens[0:10],-1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "987JnaOs5_Zc"
      },
      "source": [
        "x = torch.reshape(torch.unsqueeze(pre.tokens[0:10],-1), (10,1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEYQBEs4B0eL"
      },
      "source": [
        "y = (torch.zeros((4,1,512)).to(device), torch.zeros((4,1,512)).to(\"cpu\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhzegQWLog1H"
      },
      "source": [
        "def batchify(data, bsz):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.shape[0] // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = torch.narrow(data, 0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).contiguous()\n",
        "    # if USE_CUDA:\n",
        "    #     data = data.cuda()\n",
        "    return data\n",
        "\n",
        "\n",
        "def getBatch(data, seq_length):\n",
        "     for i in range(0, data.shape[1] - seq_length, seq_length):\n",
        "        inputs = Variable(torch.unsqueeze(data[:, i: i + seq_length], 2))\n",
        "        targets = Variable(data[:, (i + 1): (i + 1) + seq_length].contiguous())\n",
        "        # targets = torch.unsqueeze(targets, 2)\n",
        "        yield (inputs, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huEDL48fpGS1"
      },
      "source": [
        "train_data = batchify(pre.tokens, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDZRFVtUElJh",
        "outputId": "cf336ea2-7357-41a3-98e2-a12b14dfd152"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 573984])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMyNyBjusWPE",
        "outputId": "454d3361-3eb6-4964-b9b7-a19bd658a753"
      },
      "source": [
        "pre.tokens.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([146940000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwNk8uvHaOPT",
        "outputId": "521c188f-e310-4bd4-c1e6-d4ca9fbe36ef"
      },
      "source": [
        "277-93"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "184"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qykNiTqk8VgU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "963ca804-7852-4e21-a891-d894367993f8"
      },
      "source": [
        "import os\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# if os.path.exists(\"checkpoints.cp\"):\n",
        "#   print(\"The pretrained model has been found\")\n",
        "#   checkpoint = torch.load(\"checkpoints.cp\")\n",
        "#   model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#   optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#   epoch = checkpoint['epoch']\n",
        "#   loss = checkpoint['loss']\n",
        "\n",
        "# Truncated backpropagation\n",
        "def detach(states):\n",
        "    return [state.detach() for state in states] \n",
        "\n",
        "# Train the model\n",
        "train_loss = []\n",
        "plxs = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Set initial hidden and cell states\n",
        "    # states = (torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE),\n",
        "    #           torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE))\n",
        "    states = (torch.zeros(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).float().to(device),\n",
        "              torch.zeros(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).float().to(device))\n",
        "    losses = []\n",
        "    plx = []\n",
        "    for i,batch in enumerate(getBatch(train_data, SEQ_LENGTH)):\n",
        "        # Get mini-batch inputs and targets\n",
        "        inputs, targets = batch\n",
        "        # Forward pass\n",
        "        # print(i,inputs.shape, targets.shape)\n",
        "        states = detach(states)\n",
        "        outputs, states = model(inputs.float(), states)\n",
        "        # print(targets, targets.shape)\n",
        "        loss = criterion(outputs, targets.reshape(-1))\n",
        "        losses.append(loss.item())\n",
        "        plx.append(np.exp(loss.item()))\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        step = (i+1)\n",
        "        # step = (i+1) // SEQ_LENGTH\n",
        "        num_batches = train_data.shape[1] // SEQ_LENGTH\n",
        "        if step % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step[{}/{}], Loss: {:.4f}, Perplexity: {:5.2f}'\n",
        "                   .format(epoch+1, NUM_EPOCHS, step, num_batches, loss.item(), np.exp(loss.item())))\n",
        "        # break\n",
        "    ls = np.mean(losses)\n",
        "    ps = np.mean(plx)\n",
        "    train_loss.append(ls)\n",
        "    plxs.append(ps)\n",
        "    print(f\"Epoch={epoch}***********************Loss={ls}*****************Perplexity={ps}\")\n",
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, \"checkpoints.cp\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step[100/18922], Loss: 2.7438, Perplexity: 15.55\n",
            "Epoch [1/1], Step[200/18922], Loss: 2.6310, Perplexity: 13.89\n",
            "Epoch [1/1], Step[300/18922], Loss: 2.5544, Perplexity: 12.86\n",
            "Epoch [1/1], Step[400/18922], Loss: 2.4468, Perplexity: 11.55\n",
            "Epoch [1/1], Step[500/18922], Loss: 2.4000, Perplexity: 11.02\n",
            "Epoch [1/1], Step[600/18922], Loss: 2.3512, Perplexity: 10.50\n",
            "Epoch [1/1], Step[700/18922], Loss: 2.3302, Perplexity: 10.28\n",
            "Epoch [1/1], Step[800/18922], Loss: 2.2693, Perplexity:  9.67\n",
            "Epoch [1/1], Step[900/18922], Loss: 2.2168, Perplexity:  9.18\n",
            "Epoch [1/1], Step[1000/18922], Loss: 2.1969, Perplexity:  9.00\n",
            "Epoch [1/1], Step[1100/18922], Loss: 2.1783, Perplexity:  8.83\n",
            "Epoch [1/1], Step[1200/18922], Loss: 2.1055, Perplexity:  8.21\n",
            "Epoch [1/1], Step[1300/18922], Loss: 2.1237, Perplexity:  8.36\n",
            "Epoch [1/1], Step[1400/18922], Loss: 2.0427, Perplexity:  7.71\n",
            "Epoch [1/1], Step[1500/18922], Loss: 2.0450, Perplexity:  7.73\n",
            "Epoch [1/1], Step[1600/18922], Loss: 2.0393, Perplexity:  7.69\n",
            "Epoch [1/1], Step[1700/18922], Loss: 2.0054, Perplexity:  7.43\n",
            "Epoch [1/1], Step[1800/18922], Loss: 2.0341, Perplexity:  7.65\n",
            "Epoch [1/1], Step[1900/18922], Loss: 2.0191, Perplexity:  7.53\n",
            "Epoch [1/1], Step[2000/18922], Loss: 2.0066, Perplexity:  7.44\n",
            "Epoch [1/1], Step[2100/18922], Loss: 1.9383, Perplexity:  6.95\n",
            "Epoch [1/1], Step[2200/18922], Loss: 1.9886, Perplexity:  7.31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-cb45737e896f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# print(i,inputs.shape, targets.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m# print(targets, targets.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-84b7e43afaef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# print(linear.shape,\"*********\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 680\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fXoMrzBzkjz"
      },
      "source": [
        "import datetime\n",
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, f\"checkpoints_{str(int(datetime.datetime.now().timestamp()))}.cp\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoIVWRbtdgrT"
      },
      "source": [
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "  with torch.no_grad():\n",
        "    state = (torch.zeros(NUM_LAYERS, 1, HIDDEN_SIZE).float().to(device),\n",
        "              torch.zeros(NUM_LAYERS, 1, HIDDEN_SIZE).float().to(device))\n",
        "    word = prime_str\n",
        "\n",
        "    idx = pre.word2index[prime_str[-1]]\n",
        "    input = Variable(torch.Tensor([idx])).float().unsqueeze(1).to(device)\n",
        "    for i in range(predict_len):\n",
        "        # Forward propagate RNN \n",
        "        # print(input.shape)\n",
        "        output, state = model(input.unsqueeze(0), state)\n",
        "\n",
        "        # Sample a word id\n",
        "        prob = output.exp()\n",
        "        word_id = torch.multinomial(prob, num_samples=1).item()\n",
        "\n",
        "        # Fill input with sampled word id for the next time step\n",
        "        input.fill_(word_id)\n",
        "\n",
        "        # File write\n",
        "        word = word + pre.index2word[word_id]\n",
        "        # word = '\\n' if word == '<eos>' else word + ' '\n",
        "        # f.write(word)\n",
        "\n",
        "    print(word)\n",
        "    return word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_NV4uLXtrcS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "bab4283a-1c61-4910-a666-40e1dbdb3aee"
      },
      "source": [
        "txt = \"سینا عباسی\"\n",
        "evaluate(txt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "سینا عباسینرته نا غیکروا بمگات به خوبر میرت خابنا ترگ غد وي ازمامت وادث خضن کادر يمای مايتهی در سسر بو خرا دس \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'سینا عباسینرته نا غیکروا بمگات به خوبر میرت خابنا ترگ غد وي ازمامت وادث خضن کادر يمای مايتهی در سسر بو خرا دس '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s_kyAb_DBX1"
      },
      "source": [
        "### Test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atRAUynF6rdK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKyS_LcaDHkf"
      },
      "source": [
        "### **GRU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3NkiBbFDPBx"
      },
      "source": [
        "class GRULanguageModel(nn.Module):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, input_size, num_layers, output_size, hidden_size, dropout=0.25, bidirectional=False):\n",
        "    super(GRULanguageModel, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.num_layers = num_layers\n",
        "    self.output_size = output_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.dropout = dropout\n",
        "    self.bidirectional = bidirectional\n",
        "    self.lstm = nn.GRU(self.input_size, self.hidden_size, self.num_layers, dropout=self.dropout, bidirectional=self.bidirectional, batch_first=True)\n",
        "    self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
        "  \n",
        "  def forward(self, input, hidden):\n",
        "    output, _hidden = self.lstm(input, hidden)\n",
        "    linear = self.linear(output.contiguous().view(output.size(0) * output.size(1), -1))\n",
        "    # print(linear.shape,\"*********\")\n",
        "    return linear, _hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNKk7OxW3K_n"
      },
      "source": [
        "gru = GRULanguageModel(1,2,277,512).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnPcgK7o5Rey"
      },
      "source": [
        "train_data = batchify(pre.tokens, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NCZaAcNi3Vuh",
        "outputId": "1b9c2405-95e1-4479-978d-6d22b1e3020e"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(gru.parameters(), lr=learning_rate)\n",
        "\n",
        "# if os.path.exists(\"checkpoints.cp\"):\n",
        "#   print(\"The pretrained model has been found\")\n",
        "#   checkpoint = torch.load(\"checkpoints.cp\")\n",
        "#   model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#   optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#   epoch = checkpoint['epoch']\n",
        "#   loss = checkpoint['loss']\n",
        "\n",
        "# Truncated backpropagation\n",
        "def detach(states):\n",
        "    return [state.detach() for state in states] \n",
        "\n",
        "# Train the model\n",
        "train_loss = []\n",
        "plxs = []\n",
        "for epoch in range(10):\n",
        "    # Set initial hidden and cell states\n",
        "    # states = (torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE),\n",
        "    #           torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE))\n",
        "    states = torch.zeros(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).float().to(device)\n",
        "    losses = []\n",
        "    plx = []\n",
        "    for i,batch in enumerate(getBatch(train_data, SEQ_LENGTH)):\n",
        "        # Get mini-batch inputs and targets\n",
        "        inputs, targets = batch\n",
        "        # Forward pass\n",
        "        # print(i,inputs.shape, targets.shape)\n",
        "        states = states.detach()\n",
        "        outputs, states = gru(inputs.float(), states)\n",
        "        # print(targets, targets.shape)\n",
        "        loss = criterion(outputs, targets.reshape(-1))\n",
        "        losses.append(loss.item())\n",
        "        plx.append(np.exp(loss.item()))\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(gru.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        step = (i+1)\n",
        "        # step = (i+1) // SEQ_LENGTH\n",
        "        num_batches = train_data.shape[1] // SEQ_LENGTH\n",
        "        if step % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step[{}/{}], Loss: {:.4f}, Perplexity: {:5.2f}'\n",
        "                   .format(epoch+1, NUM_EPOCHS, step, num_batches, loss.item(), np.exp(loss.item())))\n",
        "        # if step%20:\n",
        "        #   break\n",
        "        # break\n",
        "    ls = np.mean(losses)\n",
        "    ps = np.mean(plx)\n",
        "    train_loss.append(ls)\n",
        "    plxs.append(ps)\n",
        "    print(f\"Epoch={epoch}***********************Loss={ls}*****************Perplexity={ps}\")\n",
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, \"checkpoints.cp\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step[100/18922], Loss: 2.5790, Perplexity: 13.18\n",
            "Epoch [1/1], Step[200/18922], Loss: 2.4012, Perplexity: 11.04\n",
            "Epoch [1/1], Step[300/18922], Loss: 2.3440, Perplexity: 10.42\n",
            "Epoch [1/1], Step[400/18922], Loss: 2.2185, Perplexity:  9.19\n",
            "Epoch [1/1], Step[500/18922], Loss: 2.2200, Perplexity:  9.21\n",
            "Epoch [1/1], Step[600/18922], Loss: 2.1504, Perplexity:  8.59\n",
            "Epoch [1/1], Step[700/18922], Loss: 2.1539, Perplexity:  8.62\n",
            "Epoch [1/1], Step[800/18922], Loss: 2.1046, Perplexity:  8.20\n",
            "Epoch [1/1], Step[900/18922], Loss: 2.0524, Perplexity:  7.79\n",
            "Epoch [1/1], Step[1000/18922], Loss: 2.0647, Perplexity:  7.88\n",
            "Epoch [1/1], Step[1100/18922], Loss: 2.0614, Perplexity:  7.86\n",
            "Epoch [1/1], Step[1200/18922], Loss: 1.9925, Perplexity:  7.33\n",
            "Epoch [1/1], Step[1300/18922], Loss: 2.0226, Perplexity:  7.56\n",
            "Epoch [1/1], Step[1400/18922], Loss: 1.9347, Perplexity:  6.92\n",
            "Epoch [1/1], Step[1500/18922], Loss: 1.9545, Perplexity:  7.06\n",
            "Epoch [1/1], Step[1600/18922], Loss: 1.9640, Perplexity:  7.13\n",
            "Epoch [1/1], Step[1700/18922], Loss: 1.9361, Perplexity:  6.93\n",
            "Epoch [1/1], Step[1800/18922], Loss: 1.9658, Perplexity:  7.14\n",
            "Epoch [1/1], Step[1900/18922], Loss: 1.9724, Perplexity:  7.19\n",
            "Epoch [1/1], Step[2000/18922], Loss: 1.9644, Perplexity:  7.13\n",
            "Epoch [1/1], Step[2100/18922], Loss: 1.8751, Perplexity:  6.52\n",
            "Epoch [1/1], Step[2200/18922], Loss: 1.9392, Perplexity:  6.95\n",
            "Epoch [1/1], Step[2300/18922], Loss: 1.8992, Perplexity:  6.68\n",
            "Epoch [1/1], Step[2400/18922], Loss: 1.9106, Perplexity:  6.76\n",
            "Epoch [1/1], Step[2500/18922], Loss: 1.8503, Perplexity:  6.36\n",
            "Epoch [1/1], Step[2600/18922], Loss: 1.8866, Perplexity:  6.60\n",
            "Epoch [1/1], Step[2700/18922], Loss: 1.8350, Perplexity:  6.27\n",
            "Epoch [1/1], Step[2800/18922], Loss: 1.8699, Perplexity:  6.49\n",
            "Epoch [1/1], Step[2900/18922], Loss: 1.8694, Perplexity:  6.48\n",
            "Epoch [1/1], Step[3000/18922], Loss: 1.8213, Perplexity:  6.18\n",
            "Epoch [1/1], Step[3100/18922], Loss: 1.8481, Perplexity:  6.35\n",
            "Epoch [1/1], Step[3200/18922], Loss: 1.8351, Perplexity:  6.27\n",
            "Epoch [1/1], Step[3300/18922], Loss: 1.8203, Perplexity:  6.17\n",
            "Epoch [1/1], Step[3400/18922], Loss: 1.7965, Perplexity:  6.03\n",
            "Epoch [1/1], Step[3500/18922], Loss: 1.7863, Perplexity:  5.97\n",
            "Epoch [1/1], Step[3600/18922], Loss: 1.8386, Perplexity:  6.29\n",
            "Epoch [1/1], Step[3700/18922], Loss: 1.8278, Perplexity:  6.22\n",
            "Epoch [1/1], Step[3800/18922], Loss: 1.8310, Perplexity:  6.24\n",
            "Epoch [1/1], Step[3900/18922], Loss: 1.8376, Perplexity:  6.28\n",
            "Epoch [1/1], Step[4000/18922], Loss: 1.8251, Perplexity:  6.20\n",
            "Epoch [1/1], Step[4100/18922], Loss: 1.8104, Perplexity:  6.11\n",
            "Epoch [1/1], Step[4200/18922], Loss: 1.8680, Perplexity:  6.48\n",
            "Epoch [1/1], Step[4300/18922], Loss: 1.7987, Perplexity:  6.04\n",
            "Epoch [1/1], Step[4400/18922], Loss: 1.7950, Perplexity:  6.02\n",
            "Epoch [1/1], Step[4500/18922], Loss: 1.8323, Perplexity:  6.25\n",
            "Epoch [1/1], Step[4600/18922], Loss: 1.7832, Perplexity:  5.95\n",
            "Epoch [1/1], Step[4700/18922], Loss: 1.8406, Perplexity:  6.30\n",
            "Epoch [1/1], Step[4800/18922], Loss: 1.7770, Perplexity:  5.91\n",
            "Epoch [1/1], Step[4900/18922], Loss: 1.8285, Perplexity:  6.22\n",
            "Epoch [1/1], Step[5000/18922], Loss: 1.8000, Perplexity:  6.05\n",
            "Epoch [1/1], Step[5100/18922], Loss: 1.7897, Perplexity:  5.99\n",
            "Epoch [1/1], Step[5200/18922], Loss: 1.7535, Perplexity:  5.77\n",
            "Epoch [1/1], Step[5300/18922], Loss: 1.7822, Perplexity:  5.94\n",
            "Epoch [1/1], Step[5400/18922], Loss: 1.8271, Perplexity:  6.22\n",
            "Epoch [1/1], Step[5500/18922], Loss: 1.8386, Perplexity:  6.29\n",
            "Epoch [1/1], Step[5600/18922], Loss: 1.8163, Perplexity:  6.15\n",
            "Epoch [1/1], Step[5700/18922], Loss: 1.7999, Perplexity:  6.05\n",
            "Epoch [1/1], Step[5800/18922], Loss: 1.7060, Perplexity:  5.51\n",
            "Epoch [1/1], Step[5900/18922], Loss: 1.6994, Perplexity:  5.47\n",
            "Epoch [1/1], Step[6000/18922], Loss: 1.7944, Perplexity:  6.02\n",
            "Epoch [1/1], Step[6100/18922], Loss: 1.7879, Perplexity:  5.98\n",
            "Epoch [1/1], Step[6200/18922], Loss: 1.7204, Perplexity:  5.59\n",
            "Epoch [1/1], Step[6300/18922], Loss: 1.7667, Perplexity:  5.85\n",
            "Epoch [1/1], Step[6400/18922], Loss: 1.7873, Perplexity:  5.97\n",
            "Epoch [1/1], Step[6500/18922], Loss: 1.7477, Perplexity:  5.74\n",
            "Epoch [1/1], Step[6600/18922], Loss: 1.7636, Perplexity:  5.83\n",
            "Epoch [1/1], Step[6700/18922], Loss: 1.7758, Perplexity:  5.91\n",
            "Epoch [1/1], Step[6800/18922], Loss: 1.7715, Perplexity:  5.88\n",
            "Epoch [1/1], Step[6900/18922], Loss: 1.7300, Perplexity:  5.64\n",
            "Epoch [1/1], Step[7000/18922], Loss: 1.7930, Perplexity:  6.01\n",
            "Epoch [1/1], Step[7100/18922], Loss: 1.7221, Perplexity:  5.60\n",
            "Epoch [1/1], Step[7200/18922], Loss: 1.8134, Perplexity:  6.13\n",
            "Epoch [1/1], Step[7300/18922], Loss: 1.7843, Perplexity:  5.96\n",
            "Epoch [1/1], Step[7400/18922], Loss: 1.7834, Perplexity:  5.95\n",
            "Epoch [1/1], Step[7500/18922], Loss: 1.6888, Perplexity:  5.41\n",
            "Epoch [1/1], Step[7600/18922], Loss: 1.7415, Perplexity:  5.71\n",
            "Epoch [1/1], Step[7700/18922], Loss: 1.7759, Perplexity:  5.91\n",
            "Epoch [1/1], Step[7800/18922], Loss: 1.7339, Perplexity:  5.66\n",
            "Epoch [1/1], Step[7900/18922], Loss: 1.7093, Perplexity:  5.53\n",
            "Epoch [1/1], Step[8000/18922], Loss: 1.7529, Perplexity:  5.77\n",
            "Epoch [1/1], Step[8100/18922], Loss: 1.7383, Perplexity:  5.69\n",
            "Epoch [1/1], Step[8200/18922], Loss: 1.7082, Perplexity:  5.52\n",
            "Epoch [1/1], Step[8300/18922], Loss: 1.7653, Perplexity:  5.84\n",
            "Epoch [1/1], Step[8400/18922], Loss: 1.7383, Perplexity:  5.69\n",
            "Epoch [1/1], Step[8500/18922], Loss: 1.7304, Perplexity:  5.64\n",
            "Epoch [1/1], Step[8600/18922], Loss: 1.6827, Perplexity:  5.38\n",
            "Epoch [1/1], Step[8700/18922], Loss: 1.7187, Perplexity:  5.58\n",
            "Epoch [1/1], Step[8800/18922], Loss: 1.7126, Perplexity:  5.54\n",
            "Epoch [1/1], Step[8900/18922], Loss: 1.7587, Perplexity:  5.80\n",
            "Epoch [1/1], Step[9000/18922], Loss: 1.7284, Perplexity:  5.63\n",
            "Epoch [1/1], Step[9100/18922], Loss: 1.7241, Perplexity:  5.61\n",
            "Epoch [1/1], Step[9200/18922], Loss: 1.7118, Perplexity:  5.54\n",
            "Epoch [1/1], Step[9300/18922], Loss: 1.7198, Perplexity:  5.58\n",
            "Epoch [1/1], Step[9400/18922], Loss: 1.6962, Perplexity:  5.45\n",
            "Epoch [1/1], Step[9500/18922], Loss: 1.6885, Perplexity:  5.41\n",
            "Epoch [1/1], Step[9600/18922], Loss: 1.7056, Perplexity:  5.50\n",
            "Epoch [1/1], Step[9700/18922], Loss: 1.7127, Perplexity:  5.54\n",
            "Epoch [1/1], Step[9800/18922], Loss: 1.6956, Perplexity:  5.45\n",
            "Epoch [1/1], Step[9900/18922], Loss: 1.7363, Perplexity:  5.68\n",
            "Epoch [1/1], Step[10000/18922], Loss: 1.7002, Perplexity:  5.47\n",
            "Epoch [1/1], Step[10100/18922], Loss: 1.7357, Perplexity:  5.67\n",
            "Epoch [1/1], Step[10200/18922], Loss: 1.7279, Perplexity:  5.63\n",
            "Epoch [1/1], Step[10300/18922], Loss: 1.6920, Perplexity:  5.43\n",
            "Epoch [1/1], Step[10400/18922], Loss: 1.7047, Perplexity:  5.50\n",
            "Epoch [1/1], Step[10500/18922], Loss: 1.7349, Perplexity:  5.67\n",
            "Epoch [1/1], Step[10600/18922], Loss: 1.6645, Perplexity:  5.28\n",
            "Epoch [1/1], Step[10700/18922], Loss: 1.6888, Perplexity:  5.41\n",
            "Epoch [1/1], Step[10800/18922], Loss: 1.7187, Perplexity:  5.58\n",
            "Epoch [1/1], Step[10900/18922], Loss: 1.7120, Perplexity:  5.54\n",
            "Epoch [1/1], Step[11000/18922], Loss: 1.7474, Perplexity:  5.74\n",
            "Epoch [1/1], Step[11100/18922], Loss: 1.6765, Perplexity:  5.35\n",
            "Epoch [1/1], Step[11200/18922], Loss: 1.7119, Perplexity:  5.54\n",
            "Epoch [1/1], Step[11300/18922], Loss: 1.6911, Perplexity:  5.43\n",
            "Epoch [1/1], Step[11400/18922], Loss: 1.7179, Perplexity:  5.57\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-6d5dabd42bbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3i-q3YE5nwm"
      },
      "source": [
        "import datetime\n",
        "torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': gru.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': loss,\n",
        "                    }, f\"./checkpoints_{str(int(datetime.datetime.now().timestamp()))}.cp\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sZHD9lv3m6j"
      },
      "source": [
        "def gru_evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "  with torch.no_grad():\n",
        "    state = torch.zeros(NUM_LAYERS, 1, HIDDEN_SIZE).float().to(device)\n",
        "    word = prime_str\n",
        "\n",
        "    idx = pre.word2index[prime_str[-1]]\n",
        "    input = Variable(torch.Tensor([idx])).float().unsqueeze(1).to(device)\n",
        "    for i in range(predict_len):\n",
        "        # Forward propagate RNN \n",
        "        # print(input.shape)\n",
        "        output, state = gru(input.unsqueeze(0), state)\n",
        "\n",
        "        # Sample a word id\n",
        "        prob = output.exp()\n",
        "        word_id = torch.multinomial(prob, num_samples=1).item()\n",
        "\n",
        "        # Fill input with sampled word id for the next time step\n",
        "        input.fill_(word_id)\n",
        "\n",
        "        # File write\n",
        "        word = word + pre.index2word[word_id]\n",
        "        # word = '\\n' if word == '<eos>' else word + ' '\n",
        "        # f.write(word)\n",
        "\n",
        "    print(word)\n",
        "    return word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "-yM0jNOdAtcZ",
        "outputId": "ed9f8801-3aab-4114-844e-88a514164aac"
      },
      "source": [
        "txt = \"سینا عباسی\"\n",
        "gru_evaluate(txt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "سینا عباسید باراني خرستهه ذلی ئو ورودان مشامف N به میرمی تنس دطووی فیست ماحاخهان است كهو افزان از N بیرج فهه م\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'سینا عباسید باراني خرستهه ذلی ئو ورودان مشامف N به میرمی تنس دطووی فیست ماحاخهان است كهو افزان از N بیرج فهه م'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgqKtTRPAy-J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z_HE92zdTds"
      },
      "source": [
        "import datetime\n",
        "\n",
        "class LanguageModelUtility:\n",
        "\n",
        "  def __init__(self, model=None, w2i=None, i2w=None, hyperparameters={}):\n",
        "    self.hyperparameters = hyperparameters\n",
        "    NUM_EPOCHS = hyperparameters.get(\"NUM_EPOCHS\", 1)\n",
        "    self.BATCH_SIZE = hyperparameters.get(\"BATCH_SIZE\", 1) \n",
        "    SEQ_LENGTH = hyperparameters.get(\"SEQ_LENGTH\", 30)\n",
        "    self.HIDDEN_SIZE = hyperparameters.get(\"HIDDEN_SIZE\", 512) \n",
        "    self.NUM_LAYERS = hyperparameters.get(\"NUM_LAYERS\", 2) \n",
        "    learning_rate = hyperparameters.get(\"learning_rate\", 0.002)\n",
        "    self.word2index = w2i\n",
        "    self.index2word = i2w\n",
        "    self.model = model\n",
        "    \n",
        "\n",
        "  @staticmethod\n",
        "  def batchify(data, bsz):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.shape[0] // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = torch.narrow(data, 0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).contiguous()\n",
        "    # if USE_CUDA:\n",
        "    #     data = data.cuda()\n",
        "    return data\n",
        "\n",
        "  @staticmethod\n",
        "  def getBatch(data, seq_length):\n",
        "      for i in range(0, data.shape[1] - seq_length, seq_length):\n",
        "          inputs = Variable(torch.unsqueeze(data[:, i: i + seq_length], 2))\n",
        "          targets = Variable(data[:, (i + 1): (i + 1) + seq_length].contiguous())\n",
        "          # targets = torch.unsqueeze(targets, 2)\n",
        "          yield (inputs, targets)\n",
        "\n",
        "  def define_model(self, model_type=\"lstm\"):\n",
        "    if model_type==\"lstm\":\n",
        "      return LanguageModel(1,2,277,512).to(device)\n",
        "    else:\n",
        "      return GRULanguageModel(1,2,277,512).to(device)\n",
        "\n",
        "  def train_char_lstm(self, model, hyperparameters, data):\n",
        "    self.hyperparameters = hyperparameters\n",
        "    NUM_EPOCHS = hyperparameters.get(\"NUM_EPOCHS\", 1)\n",
        "    self.BATCH_SIZE = hyperparameters.get(\"BATCH_SIZE\", 256) \n",
        "    SEQ_LENGTH = hyperparameters.get(\"SEQ_LENGTH\", 30)\n",
        "    self.HIDDEN_SIZE = hyperparameters.get(\"HIDDEN_SIZE\", 512) \n",
        "    self.NUM_LAYERS = hyperparameters.get(\"NUM_LAYERS\", 2) \n",
        "    learning_rate = hyperparameters.get(\"learning_rate\", 0.002)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    def detach(states):\n",
        "        return [state.detach() for state in states] \n",
        "\n",
        "    train_data = LanguageModelUtility.batchify(data, BATCH_SIZE)\n",
        "    # Train the model\n",
        "    train_loss = []\n",
        "    plxs = []\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        # Set initial hidden and cell states\n",
        "        # states = (torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE),\n",
        "        #           torch.zeros(2*NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE))\n",
        "        states = (torch.zeros(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).float().to(device),\n",
        "                  torch.zeros(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE).float().to(device))\n",
        "        losses = []\n",
        "        plx = []\n",
        "        for i,batch in enumerate(LanguageModelUtility.getBatch(train_data, SEQ_LENGTH)):\n",
        "            # Get mini-batch inputs and targets\n",
        "            inputs, targets = batch\n",
        "            # Forward pass\n",
        "            # print(i,inputs.shape, targets.shape)\n",
        "            states = detach(states)\n",
        "            outputs, states = model(inputs.float(), states)\n",
        "            # print(targets, targets.shape)\n",
        "            loss = criterion(outputs, targets.reshape(-1))\n",
        "            losses.append(loss.item())\n",
        "            plx.append(np.exp(loss.item()))\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optimizer.step()\n",
        "\n",
        "            step = (i+1)\n",
        "            # step = (i+1) // SEQ_LENGTH\n",
        "            num_batches = train_data.shape[1] // SEQ_LENGTH\n",
        "            if step % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step[{}/{}], Loss: {:.4f}, Perplexity: {:5.2f}'\n",
        "                      .format(epoch+1, NUM_EPOCHS, step, num_batches, loss.item(), np.exp(loss.item())))\n",
        "            # break\n",
        "        ls = np.mean(losses)\n",
        "        ps = np.mean(plx)\n",
        "        train_loss.append(ls)\n",
        "        plxs.append(ps)\n",
        "        print(f\"Epoch={epoch}***********************Loss={ls}*****************Perplexity={ps}\")\n",
        "        torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': loss,\n",
        "                    }, f\"./checkpoints_{str(int(datetime.datetime.now().timestamp()))}.cp\")\n",
        "  \n",
        "\n",
        "  def get_next_states_and_output(self, hidden, _input=\"ب\"):\n",
        "    with torch.no_grad():\n",
        "      def detach(states):\n",
        "        return [state.detach() for state in states]\n",
        "      \n",
        "      idx = []\n",
        "\n",
        "      for chr in _input:\n",
        "        idx.append(self.word2index[chr])\n",
        "      input = Variable(torch.Tensor(idx)).float().unsqueeze(1).to(device)\n",
        "      output, state = self.model(input.unsqueeze(0), hidden)\n",
        "      return output, state\n",
        "  \n",
        "  def convert_prefix_to_hiddens(self, init_hiddens, prefix):\n",
        "    list_of_hiddens = [init_hiddens]\n",
        "    \n",
        "    hidden = init_hiddens\n",
        "    output = None\n",
        "    for chr in prefix:\n",
        "      output , hidden = self.get_next_states_and_output(hidden, chr)\n",
        "      list_of_hiddens.append(hidden)\n",
        "    return list_of_hiddens, output\n",
        "\n",
        "  def get_probes(self, init_hiddens, prefix):\n",
        "    _, output = self.convert_prefix_to_hiddens(init_hiddens, prefix)\n",
        "    return F.softmax(output[-1].view(1,-1))\n",
        "  \n",
        "  def get_next_char(self, prefix):\n",
        "\n",
        "    states = (torch.zeros(self.NUM_LAYERS, self.BATCH_SIZE, self.HIDDEN_SIZE).float().to(device),\n",
        "              torch.zeros(self.NUM_LAYERS, self.BATCH_SIZE, self.HIDDEN_SIZE).float().to(device))\n",
        "    output, _ = self.get_next_states_and_output(states, prefix)\n",
        "    index = torch.argmax(output[-1]).item()\n",
        "    return self.index2word[index], torch.max(F.softmax(output)).item()\n",
        "\n",
        "  def generate_text(self, prefix, num_sample):\n",
        "    sent = prefix\n",
        "    for _ in range(num_sample):\n",
        "      if sent[-2:]==\"\\e\":\n",
        "        break\n",
        "      sent = sent + self.get_next_char(sent)[0]\n",
        "    return sent\n",
        "  \n",
        "  def get_overall_prob(self, sentance):\n",
        "    res = 0\n",
        "    states = (torch.zeros(self.NUM_LAYERS, self.BATCH_SIZE, self.HIDDEN_SIZE).float().to(device),\n",
        "              torch.zeros(self.NUM_LAYERS, self.BATCH_SIZE, self.HIDDEN_SIZE).float().to(device))\n",
        "    for ptr in range(len(sentance)-1):\n",
        "      prefix = sentance[ptr]\n",
        "      chr = sentance[ptr+1]\n",
        "      prob = self.get_probes(states, prefix)\n",
        "      res += np.log(prob[0][self.word2index[chr]].item())\n",
        "    return res\n",
        "  \n",
        "  def evaluate(self, prefix, target):\n",
        "    # predicted = self.generate_text(prefix, 500)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    pp = 0\n",
        "    with torch.no_grad():\n",
        "      states = (torch.zeros(NUM_LAYERS, 1, HIDDEN_SIZE).float().to(device),\n",
        "                  torch.zeros(NUM_LAYERS, 1, HIDDEN_SIZE).float().to(device))\n",
        "\n",
        "      idx = [pre.word2index[x] for x in prefix]\n",
        "      input = Variable(torch.Tensor(idx)).float().unsqueeze(1).to(device)\n",
        "      # print(len(input))\n",
        "      # import pdb;pdb.set_trace()\n",
        "      target_id = [pre.word2index.get(target[j], 0) for j in range(1,len(input)+1)]\n",
        "      target_tsn = Variable(torch.Tensor(target_id)).long().unsqueeze(1).to(device)\n",
        "      for i in range(len(target)-len(prefix)):\n",
        "          # Forward propagate RNN \n",
        "          # print(input.shape)\n",
        "          output, states = self.model(input.unsqueeze(0), states)\n",
        "          \n",
        "          # Sample a word id\n",
        "          prob = output.exp()\n",
        "          # print(input.unsqueeze(0), input.unsqueeze(0).shape)\n",
        "          # print(target_tsn, target_tsn.shape)\n",
        "          # print(output, output.shape)\n",
        "          loss = criterion(output, target_tsn.reshape(-1))\n",
        "          target_id = target_id[1:] + [pre.word2index[target[len(prefix) + 1]]]\n",
        "          target_tsn = Variable(torch.Tensor(target_id)).long().unsqueeze(1).to(device)\n",
        "          pp+=np.exp(loss.item())\n",
        "          # print(prob.shape)\n",
        "          word_id = torch.multinomial(prob[-1], num_samples=1).item()\n",
        "          # print(prob.shape, word_id)\n",
        "          input = Variable(torch.Tensor(input.squeeze().tolist()[1:] + [word_id])).float().unsqueeze(1).to(device)\n",
        "          # Fill input with sampled word id for the next time step\n",
        "          # input.f\n",
        "\n",
        "          # word = word + pre.index2word[word_id]\n",
        "    \n",
        "      return pp/(len(target)-len(prefix))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTNuGcoQIbXo"
      },
      "source": [
        "import os\n",
        "states = (torch.zeros(NUM_LAYERS, 1, HIDDEN_SIZE).float().to(device),\n",
        "                  torch.zeros(NUM_LAYERS, 1, HIDDEN_SIZE).float().to(device))\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# if os.path.exists(\"./drive/MyDrive/checkpoints_1624289195.cp\"):\n",
        "#   print(\"The pretrained model has been found\")\n",
        "#   checkpoint = torch.load(\"./drive/MyDrive/checkpoints_1624289195.cp\")\n",
        "#   model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#   optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#   epoch = checkpoint['epoch']\n",
        "#   loss = checkpoint['loss']\n",
        "util = LanguageModelUtility(model,pre.word2index, pre.index2word)\n",
        "\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGyfoM9VLqPY",
        "outputId": "bb23dc79-7268-496f-e2a2-a517606a8a9b"
      },
      "source": [
        "_input = \"ف\"\n",
        "output , next_state = util.get_next_states_and_output(states, _input)\n",
        "print(\"Output=\", output)\n",
        "print(\"Output shape=\", output.shape)\n",
        "\n",
        "print(\"hidden_state=\", next_state[0], \"Cell state=\", next_state[1])\n",
        "print(\"hidden(cell) state shape=\", next_state[0].shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output= tensor([[ 4.6075,  0.1992, -4.5678, -5.3531, -5.0582, -2.7137, -2.3740,  2.7629,\n",
            "          1.0050,  3.3218, -0.8912,  0.8100, -0.6034, -1.0316,  1.3652,  0.3856,\n",
            "          2.0447,  0.8974,  2.3673,  0.5585, -1.9625, -0.2292, -0.4599, -1.1966,\n",
            "          1.8510, -0.5564,  1.3664,  3.0950,  3.2626,  3.3074,  1.7969,  0.5155,\n",
            "          0.5588,  2.2963,  0.3217,  2.7163, -0.2603, -2.2243, -1.1806, -0.9910,\n",
            "         -3.4525, -2.1922, -1.9341,  1.8414,  2.4048, -6.3459, -6.4614, -6.7595,\n",
            "         -5.9583, -6.7817, -6.4169, -6.9276, -0.8000, -6.6361, -6.6370, -6.5746,\n",
            "         -7.0253, -6.4972,  1.5187, -6.9483, -6.8818, -6.3963, -6.6156, -6.9895,\n",
            "         -6.6762, -6.5673, -7.0769, -6.9202, -6.4102, -6.6176, -6.5587, -7.0669,\n",
            "         -6.2581, -4.3206, -6.5673, -6.1777, -6.7198, -6.5960, -6.1278, -6.5445,\n",
            "         -6.5896, -6.4745, -6.6243, -6.6407, -7.1152, -7.1129, -7.2281, -3.2284,\n",
            "         -6.8362, -6.6189, -5.9691, -6.5603, -6.8416, -6.8326, -6.6945, -6.8182,\n",
            "         -6.6819, -5.3772, -6.6414, -6.6418, -6.7299, -6.7124, -6.1977, -5.3034,\n",
            "         -6.5705, -6.2644, -6.5971, -6.4026, -3.6722, -3.6070, -1.2017, -7.7324,\n",
            "         -3.2538, -2.1177, -3.8616, -1.9935, -5.0949, -6.4519, -3.2384, -0.9777,\n",
            "         -2.4312, -3.2326, -3.7919, -3.5682, -3.9087, -4.1048, -3.3055, -2.6519,\n",
            "         -3.2769, -2.0137, -3.2564, -3.1285, -2.0594, -1.3745, -5.7205, -3.9417,\n",
            "         -6.3277, -6.6823, -6.5787, -6.3291, -1.2060, -4.0937, -6.6117, -6.6599,\n",
            "         -4.6501, -2.4718, -4.7208, -3.0585, -1.5694, -1.8543, -6.3357, -5.4947,\n",
            "         -6.8446, -3.8448, -4.1092, -5.3678, -3.7461, -6.6587, -2.2195, -3.2283,\n",
            "         -6.2353, -6.3558, -5.3069, -6.7900, -6.7383, -3.1270, -6.8929, -7.0329,\n",
            "         -4.3185, -3.6001, -5.1533, -6.2698, -7.0357, -3.5138, -2.4544, -1.8537,\n",
            "         -2.3241, -3.6476, -2.8342, -4.0773, -6.7291, -5.4384, -6.5188, -6.8438,\n",
            "         -4.4443, -5.7930, -6.7631, -6.7714, -4.5482, -1.4718, -4.3649, -4.5882,\n",
            "         -3.6424, -6.6801, -1.7822, -2.0042, -2.4692, -6.6576, -4.7328, -3.9746,\n",
            "         -6.5998, -6.6532, -4.5706, -3.9868, -2.5769, -2.3960, -3.6112, -3.2877,\n",
            "         -3.4379, -6.3011, -6.7046, -6.1564, -6.9092, -4.3464, -6.6365, -6.7064,\n",
            "         -6.6528, -5.1446, -6.5288, -6.1568, -6.7835, -6.3801, -6.8296, -5.4105,\n",
            "         -6.8152, -6.6247, -6.6413, -4.7615, -4.6173, -6.1139, -4.4720, -6.3154,\n",
            "         -3.8199, -4.7718, -6.5335, -7.0195, -5.8107, -6.6738, -6.8949, -6.7812,\n",
            "         -6.4692, -6.3924, -6.5563, -6.3972, -6.8688, -6.7546, -6.7861, -6.7873,\n",
            "         -6.3823, -6.9114, -6.4559, -6.4487, -6.7403, -6.6054, -6.6716, -6.7063,\n",
            "         -6.7617, -6.8307, -6.7461, -6.5443, -6.5915, -6.2798, -6.5893, -6.7769,\n",
            "         -4.7889, -6.4825, -6.6007, -6.3182, -6.7663, -7.1850, -6.8566, -6.3247,\n",
            "         -6.6220, -6.4795, -6.8236, -6.7634, -6.7949]])\n",
            "Output shape= torch.Size([1, 277])\n",
            "hidden_state= tensor([[[-2.0199e-02, -1.8881e-03, -4.7276e-03,  ..., -8.3166e-04,\n",
            "          -2.0093e-01, -9.5539e-02]],\n",
            "\n",
            "        [[-1.5695e-01,  1.8381e-03, -4.5737e-08,  ...,  1.9234e-01,\n",
            "           5.6871e-17, -1.0173e-04]]]) Cell state= tensor([[[-2.9303e-01, -3.0458e-01, -2.2485e-01,  ..., -4.3065e-01,\n",
            "          -3.6108e-01, -4.4730e-01]],\n",
            "\n",
            "        [[-8.3800e-01,  1.7499e-02, -1.2143e-04,  ...,  2.0382e-01,\n",
            "           2.9060e-09, -3.0726e-03]]])\n",
            "hidden(cell) state shape= torch.Size([2, 1, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWtvbVHlMVNV",
        "outputId": "4f96375d-05b7-4418-8494-9acca69112f7"
      },
      "source": [
        "_input = \"فا\"\n",
        "output , next_state = util.get_next_states_and_output(states, _input)\n",
        "print(\"Output=\", output)\n",
        "print(\"Output shape=\", output.shape)\n",
        "\n",
        "print(\"hidden_state=\", next_state[0], \"Cell state=\", next_state[1])\n",
        "print(\"hidden(cell) state shape=\", next_state[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output= tensor([[  4.5170,   0.3484,  -4.6409,  -5.6567,  -5.1305,  -2.8607,  -2.1282,\n",
            "           2.8689,   1.7849,   3.3922,  -0.6367,   1.2038,  -0.3218,  -0.8052,\n",
            "           2.1555,   0.5042,   1.6683,   1.5742,   1.6980,   0.3958,  -1.6498,\n",
            "          -0.6050,  -0.0295,  -0.5895,   1.9981,   0.0533,   1.4768,   2.8811,\n",
            "           2.9274,   3.8882,   1.7446,   1.1503,   0.1581,   2.1992,   0.8507,\n",
            "           2.4801,   0.2106,  -1.9189,  -1.8717,  -0.9983,  -3.3818,  -2.2375,\n",
            "          -2.1188,   1.6977,   2.1969,  -6.5221,  -6.5589,  -6.8761,  -6.0544,\n",
            "          -6.8995,  -6.5690,  -7.0897,  -1.0445,  -6.7279,  -6.7388,  -6.6783,\n",
            "          -7.1426,  -6.5217,   1.4406,  -7.0531,  -7.0495,  -6.5243,  -6.7443,\n",
            "          -7.0899,  -6.7888,  -6.6538,  -7.1671,  -7.0122,  -6.5364,  -6.7313,\n",
            "          -6.6384,  -7.1408,  -6.3611,  -4.4432,  -6.7170,  -6.2917,  -6.8026,\n",
            "          -6.7487,  -6.2280,  -6.6931,  -6.7666,  -6.5941,  -6.7713,  -6.7370,\n",
            "          -7.1950,  -7.2100,  -7.3709,  -3.1393,  -6.9524,  -6.6965,  -6.0598,\n",
            "          -6.6773,  -6.9133,  -6.9920,  -6.7813,  -6.9894,  -6.8052,  -5.4988,\n",
            "          -6.7429,  -6.7329,  -6.8376,  -6.8547,  -6.3709,  -5.2046,  -6.6722,\n",
            "          -6.3563,  -6.6791,  -6.5004,  -3.9032,  -3.9855,  -1.5902,  -7.8378,\n",
            "          -3.4570,  -2.3189,  -4.0148,  -2.3327,  -5.1711,  -6.6172,  -3.3608,\n",
            "          -1.4741,  -2.7412,  -3.4021,  -4.0012,  -3.7496,  -4.1197,  -4.2432,\n",
            "          -3.5162,  -2.9633,  -3.4039,  -2.2791,  -3.4992,  -3.4504,  -2.5305,\n",
            "          -1.7486,  -5.8855,  -4.1358,  -6.4255,  -6.7890,  -6.7563,  -6.4910,\n",
            "          -1.5042,  -4.1934,  -6.7730,  -6.7285,  -4.7856,  -2.7132,  -4.8118,\n",
            "          -3.2514,  -1.8290,  -2.1889,  -6.4523,  -5.6026,  -6.9554,  -4.0160,\n",
            "          -4.2432,  -5.5411,  -3.9594,  -6.7651,  -2.4062,  -3.3746,  -6.3809,\n",
            "          -6.5202,  -5.3931,  -6.9069,  -6.8450,  -3.3014,  -7.0322,  -7.1458,\n",
            "          -4.4796,  -3.8291,  -5.2922,  -6.4230,  -7.1591,  -3.5865,  -2.6657,\n",
            "          -2.1177,  -2.6655,  -3.7067,  -3.0904,  -4.2336,  -6.8492,  -5.5025,\n",
            "          -6.6519,  -6.9268,  -4.7170,  -5.9438,  -6.8424,  -6.9161,  -4.6047,\n",
            "          -1.7605,  -4.5517,  -4.6975,  -3.8271,  -6.7767,  -2.1216,  -2.4012,\n",
            "          -2.7286,  -6.7410,  -4.8483,  -4.1769,  -6.7117,  -6.7711,  -4.6745,\n",
            "          -4.1568,  -2.7849,  -2.7044,  -3.7990,  -3.5163,  -3.5284,  -6.4573,\n",
            "          -6.7972,  -6.2726,  -7.0041,  -4.4875,  -6.7749,  -6.8791,  -6.7488,\n",
            "          -5.2859,  -6.6335,  -6.2411,  -6.8849,  -6.4333,  -6.9279,  -5.5051,\n",
            "          -6.8846,  -6.7037,  -6.7580,  -4.9005,  -4.7468,  -6.2420,  -4.6150,\n",
            "          -6.3570,  -3.9387,  -4.8533,  -6.5836,  -7.1164,  -5.9104,  -6.7695,\n",
            "          -7.0238,  -6.8903,  -6.5630,  -6.5174,  -6.6647,  -6.5266,  -7.0027,\n",
            "          -6.8819,  -6.9150,  -6.9190,  -6.5070,  -6.9596,  -6.5761,  -6.5806,\n",
            "          -6.9129,  -6.7204,  -6.7928,  -6.7934,  -6.9092,  -6.9882,  -6.9138,\n",
            "          -6.6651,  -6.6872,  -6.3837,  -6.7034,  -6.8857,  -4.9780,  -6.6109,\n",
            "          -6.7503,  -6.3771,  -6.8461,  -7.3176,  -6.9695,  -6.4553,  -6.7360,\n",
            "          -6.5844,  -6.9146,  -6.9202,  -6.9539],\n",
            "        [  5.8547,  -1.4965, -10.4447, -11.5473, -10.9724,  -0.2038,  -1.1827,\n",
            "           6.2133,   3.4800,   5.2058,  -3.7268,   1.2108,  -0.5372,   1.6891,\n",
            "           3.8675,  -0.9959,   2.6095,   0.3827,   2.1956,   1.9388,  -3.1959,\n",
            "          -0.9985,  -0.5784,  -0.2759,   1.5987,  -0.7482,   1.4594,   3.6589,\n",
            "           5.6929,   2.3215,   6.1872,   1.2570,   1.2250,   3.3350,   1.7096,\n",
            "           4.4248,  -1.4463,  -1.5931,   0.1261,   0.4945,  -3.7454,  -3.8534,\n",
            "          -3.0192,   2.8687,   3.0145, -10.9916, -10.6083, -11.2521, -10.4697,\n",
            "         -11.4155, -11.0882, -11.2107,  -4.4251, -11.1535, -11.1169, -10.8483,\n",
            "         -11.5967, -10.9069,   1.7244, -11.6923, -11.2875, -11.1153, -10.9220,\n",
            "         -11.7132, -11.0401, -11.1550, -11.5591, -11.4329, -11.3356, -11.0858,\n",
            "         -11.0280, -11.5471, -10.7040,  -6.8537, -11.3129, -10.6477, -11.1234,\n",
            "         -10.9597, -10.7658, -11.0248, -11.0685, -11.1754, -11.0315, -11.2557,\n",
            "         -11.5253, -11.7341, -11.9268,  -5.7397, -11.2973, -11.2131, -10.3762,\n",
            "         -11.2073, -11.4383, -11.4136, -11.1117, -11.2821, -11.2160,  -8.6500,\n",
            "         -11.2699, -11.1395, -11.4618, -11.1370, -10.7560,  -9.6740, -11.2756,\n",
            "         -10.4756, -10.4412,  -9.6897,  -9.4358, -13.5245, -10.7819, -11.8325,\n",
            "          -9.8876,  -9.2175,  -8.4216,  -9.8970,  -8.8315, -10.8824,  -9.2431,\n",
            "         -10.9770,  -8.7348,  -9.2257,  -8.9231, -10.5313,  -9.8654,  -8.4766,\n",
            "          -9.3830, -11.0978,  -7.3841,  -9.5336,  -9.8188, -11.6754, -10.5563,\n",
            "         -11.7658, -10.6935,  -9.7693, -10.9839, -11.2761, -11.6074, -10.8453,\n",
            "          -9.5740,  -9.5287, -11.2020, -11.2886,  -9.3294,  -9.4890,  -9.1439,\n",
            "          -9.3863,  -9.2770,  -9.2606, -10.7920, -10.2199, -11.5753,  -9.5290,\n",
            "          -8.0792, -10.4242,  -9.5131, -11.6268,  -8.2580,  -9.3866, -10.6006,\n",
            "         -10.7517, -10.0200, -11.1892, -11.1169,  -8.8822, -11.5250, -11.2842,\n",
            "          -9.3114, -10.4800,  -9.8663, -10.2449, -11.3476,  -8.7589, -10.3409,\n",
            "          -9.3272, -10.6168,  -7.7105,  -9.4211,  -9.2180, -11.4503,  -9.0199,\n",
            "         -11.2598, -11.5266, -11.4876, -10.3541, -11.2487, -11.2956,  -9.2306,\n",
            "          -8.4111, -11.7357,  -8.9831,  -8.8244, -11.0104,  -8.0395,  -9.3525,\n",
            "          -9.0841, -11.1282,  -9.3346,  -9.2951, -11.2217, -11.1241,  -9.2638,\n",
            "          -9.0040,  -8.9761,  -8.8376, -10.8373,  -9.3418,  -8.6620, -11.0660,\n",
            "         -11.1913, -10.6160, -11.2879,  -9.3217, -11.0678, -11.2132, -11.1405,\n",
            "          -9.8197, -10.5696, -10.4395, -11.3816, -10.9210, -11.4079,  -9.8697,\n",
            "         -11.3422, -11.2555, -11.0656,  -8.9861,  -9.5650, -10.5127,  -9.1772,\n",
            "         -10.3055,  -9.6236,  -8.8825, -11.1460, -11.6355, -10.1592, -11.1152,\n",
            "         -11.4705, -11.1440, -10.8209, -11.0926, -11.1180, -10.9963, -11.6885,\n",
            "         -11.3447, -11.5671, -11.4855, -10.4571, -11.3868, -11.3044, -11.1069,\n",
            "         -11.1052, -11.1597, -11.3452, -11.4740, -11.3055, -11.5680, -11.2051,\n",
            "         -10.9518, -11.0313, -10.4676, -11.2754, -11.2103,  -9.3931, -10.9366,\n",
            "         -11.0641, -10.6707, -11.0150, -11.7912, -11.4164, -11.1506, -11.1177,\n",
            "         -10.6506, -10.9886, -11.1196, -11.3665]])\n",
            "Output shape= torch.Size([2, 277])\n",
            "hidden_state= tensor([[[-5.0409e-03, -7.2002e-01, -6.6328e-01,  ..., -4.8946e-01,\n",
            "          -7.7167e-01, -1.1736e-01]],\n",
            "\n",
            "        [[-4.6183e-01, -4.4366e-08, -2.2851e-16,  ..., -6.2137e-01,\n",
            "           8.4822e-15, -4.0240e-14]]]) Cell state= tensor([[[-1.1059e+00, -1.1334e+00, -1.0267e+00,  ..., -8.9240e-01,\n",
            "          -1.1121e+00, -1.2038e+00]],\n",
            "\n",
            "        [[-1.8629e+00, -3.4048e-04, -5.5178e-09,  ..., -7.2726e-01,\n",
            "           3.0715e-07, -3.7082e-07]]])\n",
            "hidden(cell) state shape= torch.Size([2, 1, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMxcBftEPFLP",
        "outputId": "f8da65d8-9f3c-4cb7-a19c-c73433c7a7e8"
      },
      "source": [
        "_input = \"فا\"\n",
        "hiddens , outout = util.convert_prefix_to_hiddens(states, _input)\n",
        "print(\"hidden=\", hiddens)\n",
        "print(\"hiddens length=\", len(hiddens))\n",
        "print(\"hidden[1]=\", hiddens[1])\n",
        "\n",
        "print(\"output=\",output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden= [(tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]]])), (tensor([[[-2.0199e-02, -1.8881e-03, -4.7276e-03,  ..., -8.3166e-04,\n",
            "          -2.0093e-01, -9.5539e-02]],\n",
            "\n",
            "        [[-2.4794e-01, -1.6078e-03, -1.2269e-07,  ...,  1.4866e-01,\n",
            "           9.7701e-15, -3.7643e-05]]]), tensor([[[-2.9303e-01, -3.0458e-01, -2.2485e-01,  ..., -4.3065e-01,\n",
            "          -3.6108e-01, -4.4730e-01]],\n",
            "\n",
            "        [[-8.2873e-01, -1.3999e-02, -2.8136e-04,  ...,  1.5303e-01,\n",
            "           3.4087e-08, -1.1355e-03]]])), (tensor([[[-5.0409e-03, -7.2002e-01, -6.6328e-01,  ..., -4.8946e-01,\n",
            "          -7.7167e-01, -1.1736e-01]],\n",
            "\n",
            "        [[-7.7945e-02, -6.6050e-08, -1.5352e-15,  ..., -6.6687e-01,\n",
            "           7.3510e-13, -1.7651e-14]]]), tensor([[[-1.1059e+00, -1.1334e+00, -1.0267e+00,  ..., -8.9240e-01,\n",
            "          -1.1121e+00, -1.2038e+00]],\n",
            "\n",
            "        [[-1.8188e+00, -6.0880e-04, -1.1080e-08,  ..., -8.0616e-01,\n",
            "           3.9260e-06, -1.7985e-07]]]))]\n",
            "hiddens length= 3\n",
            "hidden[1]= (tensor([[[-2.0199e-02, -1.8881e-03, -4.7276e-03,  ..., -8.3166e-04,\n",
            "          -2.0093e-01, -9.5539e-02]],\n",
            "\n",
            "        [[-2.4794e-01, -1.6078e-03, -1.2269e-07,  ...,  1.4866e-01,\n",
            "           9.7701e-15, -3.7643e-05]]]), tensor([[[-2.9303e-01, -3.0458e-01, -2.2485e-01,  ..., -4.3065e-01,\n",
            "          -3.6108e-01, -4.4730e-01]],\n",
            "\n",
            "        [[-8.2873e-01, -1.3999e-02, -2.8136e-04,  ...,  1.5303e-01,\n",
            "           3.4087e-08, -1.1355e-03]]]))\n",
            "output= tensor([[  4.5170,   0.3484,  -4.6409,  -5.6567,  -5.1305,  -2.8607,  -2.1282,\n",
            "           2.8689,   1.7849,   3.3922,  -0.6367,   1.2038,  -0.3218,  -0.8052,\n",
            "           2.1555,   0.5042,   1.6683,   1.5742,   1.6980,   0.3958,  -1.6498,\n",
            "          -0.6050,  -0.0295,  -0.5895,   1.9981,   0.0533,   1.4768,   2.8811,\n",
            "           2.9274,   3.8882,   1.7446,   1.1503,   0.1581,   2.1992,   0.8507,\n",
            "           2.4801,   0.2106,  -1.9189,  -1.8717,  -0.9983,  -3.3818,  -2.2375,\n",
            "          -2.1188,   1.6977,   2.1969,  -6.5221,  -6.5589,  -6.8761,  -6.0544,\n",
            "          -6.8995,  -6.5690,  -7.0897,  -1.0445,  -6.7279,  -6.7388,  -6.6783,\n",
            "          -7.1426,  -6.5217,   1.4406,  -7.0531,  -7.0495,  -6.5243,  -6.7443,\n",
            "          -7.0899,  -6.7888,  -6.6538,  -7.1671,  -7.0122,  -6.5364,  -6.7313,\n",
            "          -6.6384,  -7.1408,  -6.3611,  -4.4432,  -6.7170,  -6.2917,  -6.8026,\n",
            "          -6.7487,  -6.2280,  -6.6931,  -6.7666,  -6.5941,  -6.7713,  -6.7370,\n",
            "          -7.1950,  -7.2100,  -7.3709,  -3.1393,  -6.9524,  -6.6965,  -6.0598,\n",
            "          -6.6773,  -6.9133,  -6.9920,  -6.7813,  -6.9894,  -6.8052,  -5.4988,\n",
            "          -6.7429,  -6.7329,  -6.8376,  -6.8547,  -6.3709,  -5.2046,  -6.6722,\n",
            "          -6.3563,  -6.6791,  -6.5004,  -3.9032,  -3.9855,  -1.5902,  -7.8378,\n",
            "          -3.4570,  -2.3189,  -4.0148,  -2.3327,  -5.1711,  -6.6172,  -3.3608,\n",
            "          -1.4741,  -2.7412,  -3.4021,  -4.0012,  -3.7496,  -4.1197,  -4.2432,\n",
            "          -3.5162,  -2.9633,  -3.4039,  -2.2791,  -3.4992,  -3.4504,  -2.5305,\n",
            "          -1.7486,  -5.8855,  -4.1358,  -6.4255,  -6.7890,  -6.7563,  -6.4910,\n",
            "          -1.5042,  -4.1934,  -6.7730,  -6.7285,  -4.7856,  -2.7132,  -4.8118,\n",
            "          -3.2514,  -1.8290,  -2.1889,  -6.4523,  -5.6026,  -6.9554,  -4.0160,\n",
            "          -4.2432,  -5.5411,  -3.9594,  -6.7651,  -2.4062,  -3.3746,  -6.3809,\n",
            "          -6.5202,  -5.3931,  -6.9069,  -6.8450,  -3.3014,  -7.0322,  -7.1458,\n",
            "          -4.4796,  -3.8291,  -5.2922,  -6.4230,  -7.1591,  -3.5865,  -2.6657,\n",
            "          -2.1177,  -2.6655,  -3.7067,  -3.0904,  -4.2336,  -6.8492,  -5.5025,\n",
            "          -6.6519,  -6.9268,  -4.7170,  -5.9438,  -6.8424,  -6.9161,  -4.6047,\n",
            "          -1.7605,  -4.5517,  -4.6975,  -3.8271,  -6.7767,  -2.1216,  -2.4012,\n",
            "          -2.7286,  -6.7410,  -4.8483,  -4.1769,  -6.7117,  -6.7711,  -4.6745,\n",
            "          -4.1568,  -2.7849,  -2.7044,  -3.7990,  -3.5163,  -3.5284,  -6.4573,\n",
            "          -6.7972,  -6.2726,  -7.0041,  -4.4875,  -6.7749,  -6.8791,  -6.7488,\n",
            "          -5.2859,  -6.6335,  -6.2411,  -6.8849,  -6.4333,  -6.9279,  -5.5051,\n",
            "          -6.8846,  -6.7037,  -6.7580,  -4.9005,  -4.7468,  -6.2420,  -4.6150,\n",
            "          -6.3570,  -3.9387,  -4.8533,  -6.5836,  -7.1164,  -5.9104,  -6.7695,\n",
            "          -7.0238,  -6.8903,  -6.5630,  -6.5174,  -6.6647,  -6.5266,  -7.0027,\n",
            "          -6.8819,  -6.9150,  -6.9190,  -6.5070,  -6.9596,  -6.5761,  -6.5806,\n",
            "          -6.9129,  -6.7204,  -6.7928,  -6.7934,  -6.9092,  -6.9882,  -6.9138,\n",
            "          -6.6651,  -6.6872,  -6.3837,  -6.7034,  -6.8857,  -4.9780,  -6.6109,\n",
            "          -6.7503,  -6.3771,  -6.8461,  -7.3176,  -6.9695,  -6.4553,  -6.7360,\n",
            "          -6.5844,  -6.9146,  -6.9202,  -6.9539],\n",
            "        [  5.8547,  -1.4965, -10.4447, -11.5473, -10.9724,  -0.2038,  -1.1827,\n",
            "           6.2133,   3.4800,   5.2058,  -3.7268,   1.2108,  -0.5372,   1.6891,\n",
            "           3.8675,  -0.9959,   2.6095,   0.3827,   2.1956,   1.9388,  -3.1959,\n",
            "          -0.9985,  -0.5784,  -0.2759,   1.5987,  -0.7482,   1.4594,   3.6589,\n",
            "           5.6929,   2.3215,   6.1872,   1.2570,   1.2250,   3.3350,   1.7096,\n",
            "           4.4248,  -1.4463,  -1.5931,   0.1261,   0.4945,  -3.7454,  -3.8534,\n",
            "          -3.0192,   2.8687,   3.0145, -10.9916, -10.6083, -11.2521, -10.4697,\n",
            "         -11.4155, -11.0882, -11.2107,  -4.4251, -11.1535, -11.1169, -10.8483,\n",
            "         -11.5967, -10.9069,   1.7244, -11.6923, -11.2875, -11.1153, -10.9220,\n",
            "         -11.7132, -11.0401, -11.1550, -11.5591, -11.4329, -11.3356, -11.0858,\n",
            "         -11.0280, -11.5471, -10.7040,  -6.8537, -11.3129, -10.6477, -11.1234,\n",
            "         -10.9597, -10.7658, -11.0248, -11.0685, -11.1754, -11.0315, -11.2557,\n",
            "         -11.5253, -11.7341, -11.9268,  -5.7397, -11.2973, -11.2131, -10.3762,\n",
            "         -11.2073, -11.4383, -11.4136, -11.1117, -11.2821, -11.2160,  -8.6500,\n",
            "         -11.2699, -11.1395, -11.4618, -11.1370, -10.7560,  -9.6740, -11.2756,\n",
            "         -10.4756, -10.4412,  -9.6897,  -9.4358, -13.5245, -10.7819, -11.8325,\n",
            "          -9.8876,  -9.2175,  -8.4216,  -9.8970,  -8.8315, -10.8824,  -9.2431,\n",
            "         -10.9770,  -8.7348,  -9.2257,  -8.9231, -10.5313,  -9.8654,  -8.4766,\n",
            "          -9.3830, -11.0978,  -7.3841,  -9.5336,  -9.8188, -11.6754, -10.5563,\n",
            "         -11.7658, -10.6935,  -9.7693, -10.9839, -11.2761, -11.6074, -10.8453,\n",
            "          -9.5740,  -9.5287, -11.2020, -11.2886,  -9.3294,  -9.4890,  -9.1439,\n",
            "          -9.3863,  -9.2770,  -9.2606, -10.7920, -10.2199, -11.5753,  -9.5290,\n",
            "          -8.0792, -10.4242,  -9.5131, -11.6268,  -8.2580,  -9.3866, -10.6006,\n",
            "         -10.7517, -10.0200, -11.1892, -11.1169,  -8.8822, -11.5250, -11.2842,\n",
            "          -9.3114, -10.4800,  -9.8663, -10.2449, -11.3476,  -8.7589, -10.3409,\n",
            "          -9.3272, -10.6168,  -7.7105,  -9.4211,  -9.2180, -11.4503,  -9.0199,\n",
            "         -11.2598, -11.5266, -11.4876, -10.3541, -11.2487, -11.2956,  -9.2306,\n",
            "          -8.4111, -11.7357,  -8.9831,  -8.8244, -11.0104,  -8.0395,  -9.3525,\n",
            "          -9.0841, -11.1282,  -9.3346,  -9.2951, -11.2217, -11.1241,  -9.2638,\n",
            "          -9.0040,  -8.9761,  -8.8376, -10.8373,  -9.3418,  -8.6620, -11.0660,\n",
            "         -11.1913, -10.6160, -11.2879,  -9.3217, -11.0678, -11.2132, -11.1405,\n",
            "          -9.8197, -10.5696, -10.4395, -11.3816, -10.9210, -11.4079,  -9.8697,\n",
            "         -11.3422, -11.2555, -11.0656,  -8.9861,  -9.5650, -10.5127,  -9.1772,\n",
            "         -10.3055,  -9.6236,  -8.8825, -11.1460, -11.6355, -10.1592, -11.1152,\n",
            "         -11.4705, -11.1440, -10.8209, -11.0926, -11.1180, -10.9963, -11.6885,\n",
            "         -11.3447, -11.5671, -11.4855, -10.4571, -11.3868, -11.3044, -11.1069,\n",
            "         -11.1052, -11.1597, -11.3452, -11.4740, -11.3055, -11.5680, -11.2051,\n",
            "         -10.9518, -11.0313, -10.4676, -11.2754, -11.2103,  -9.3931, -10.9366,\n",
            "         -11.0641, -10.6707, -11.0150, -11.7912, -11.4164, -11.1506, -11.1177,\n",
            "         -10.6506, -10.9886, -11.1196, -11.3665]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNg9wJHoUR-N",
        "outputId": "6dccbbf5-05ba-4a1e-beb3-0a869bc142e1"
      },
      "source": [
        "_input = \"فا\"\n",
        "outout = util.get_probes(states, _input)\n",
        "print(f\"Input=========={_input}\")\n",
        "print(\"probes=\", outout)\n",
        "print(\"Sum of probes are=\",outout.sum().item())\n",
        "\n",
        "\n",
        "_input = \"من\"\n",
        "outout = util.get_probes(states, _input)\n",
        "print(f\"Input=========={_input}\")\n",
        "print(\"probes=\", outout)\n",
        "print(\"Sum of probes are=\",outout.sum().item())\n",
        "\n",
        "_input = \"شهر\"\n",
        "outout = util.get_probes(states, _input)\n",
        "print(f\"Input=========={_input}\")\n",
        "print(\"probes=\", outout)\n",
        "print(\"Sum of probes are=\",outout.sum().item())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input==========فا\n",
            "probes= tensor([[9.1109e-02, 9.7424e-05, 2.5147e-08, 9.8989e-09, 2.3674e-08, 3.2797e-04,\n",
            "         2.2212e-04, 1.6881e-01, 1.4430e-02, 1.1877e-01, 3.7593e-05, 1.7546e-03,\n",
            "         9.1116e-04, 2.7495e-03, 5.1654e-02, 1.2330e-04, 9.4157e-03, 2.0700e-03,\n",
            "         5.4984e-03, 5.1233e-03, 7.0256e-05, 3.5753e-04, 8.2234e-04, 5.4287e-04,\n",
            "         5.0699e-03, 5.3120e-04, 2.1894e-03, 3.2470e-02, 1.0267e-01, 5.4284e-03,\n",
            "         2.4165e-01, 4.1696e-03, 1.6926e-03, 1.9156e-02, 5.1333e-03, 7.6015e-02,\n",
            "         1.4346e-04, 2.0183e-04, 6.5174e-04, 1.2997e-03, 1.6920e-05, 1.0155e-05,\n",
            "         3.8765e-05, 6.8507e-03, 1.4694e-02, 1.1729e-08, 1.8839e-08, 1.0477e-08,\n",
            "         2.1692e-08, 8.0400e-09, 1.0831e-08, 9.5098e-09, 8.0102e-06, 1.1105e-08,\n",
            "         1.0344e-08, 1.4758e-08, 7.1342e-09, 1.3939e-08, 5.0024e-03, 6.3114e-09,\n",
            "         1.0244e-08, 1.2359e-08, 1.3839e-08, 6.0949e-09, 1.3354e-08, 1.1834e-08,\n",
            "         7.9888e-09, 9.3583e-09, 9.4502e-09, 1.1412e-08, 1.1753e-08, 7.3832e-09,\n",
            "         1.7929e-08, 8.1322e-07, 9.5372e-09, 1.7288e-08, 1.1198e-08, 1.2904e-08,\n",
            "         1.5108e-08, 1.2674e-08, 1.3125e-08, 1.1097e-08, 1.3218e-08, 1.0239e-08,\n",
            "         7.5052e-09, 5.5820e-09, 5.2276e-09, 1.6689e-06, 9.2296e-09, 9.7661e-09,\n",
            "         2.1051e-08, 1.0042e-08, 8.9260e-09, 9.4349e-09, 1.1298e-08, 1.0252e-08,\n",
            "         9.8495e-09, 1.2461e-07, 1.0848e-08, 1.0724e-08, 8.8887e-09, 1.0960e-08,\n",
            "         1.6889e-08, 5.1298e-08, 9.5895e-09, 2.3225e-08, 2.5233e-08, 6.2149e-08,\n",
            "         6.1587e-08, 1.0027e-09, 1.6915e-08, 8.1875e-09, 3.5918e-08, 7.3984e-08,\n",
            "         1.9131e-07, 3.9944e-08, 1.2767e-07, 1.6486e-08, 6.9606e-08, 1.3236e-08,\n",
            "         1.3298e-07, 7.1703e-08, 9.3532e-08, 1.9875e-08, 3.7025e-08, 1.5649e-07,\n",
            "         5.7594e-08, 1.1419e-08, 5.6771e-07, 5.3337e-08, 4.4141e-08, 7.4804e-09,\n",
            "         1.4995e-08, 6.4397e-09, 1.6282e-08, 4.2120e-08, 1.2878e-08, 9.1892e-09,\n",
            "         7.8048e-09, 1.4470e-08, 4.8134e-08, 5.2342e-08, 1.0259e-08, 1.0571e-08,\n",
            "         5.8723e-08, 5.6793e-08, 7.8461e-08, 6.4106e-08, 6.7796e-08, 6.8251e-08,\n",
            "         1.4946e-08, 2.7647e-08, 6.9909e-09, 4.9595e-08, 2.4645e-07, 2.1567e-08,\n",
            "         5.3352e-08, 6.7312e-09, 1.9329e-07, 5.6242e-08, 2.1438e-08, 1.5857e-08,\n",
            "         3.6085e-08, 1.1461e-08, 1.1345e-08, 1.0743e-07, 8.1763e-09, 9.1116e-09,\n",
            "         6.5102e-08, 2.0104e-08, 3.8656e-08, 2.6586e-08, 9.1468e-09, 1.1329e-07,\n",
            "         2.8375e-08, 6.2484e-08, 1.6497e-08, 3.4682e-07, 5.3509e-08, 6.5447e-08,\n",
            "         8.6711e-09, 8.7811e-08, 9.4530e-09, 7.8951e-09, 7.1340e-09, 2.5863e-08,\n",
            "         9.5092e-09, 9.9663e-09, 7.4412e-08, 1.6041e-07, 6.1464e-09, 9.8052e-08,\n",
            "         1.1087e-07, 1.1865e-08, 2.6148e-07, 6.2809e-08, 7.7295e-08, 1.0503e-08,\n",
            "         6.5444e-08, 6.4804e-08, 9.9194e-09, 1.2858e-08, 6.6905e-08, 8.2551e-08,\n",
            "         8.1791e-08, 9.8315e-08, 1.3388e-08, 7.2498e-08, 1.2177e-07, 1.1727e-08,\n",
            "         1.0973e-08, 1.8013e-08, 8.8433e-09, 6.4778e-08, 1.1575e-08, 9.2534e-09,\n",
            "         1.0173e-08, 3.9385e-08, 1.8314e-08, 2.3305e-08, 8.5813e-09, 1.4285e-08,\n",
            "         9.0256e-09, 3.7398e-08, 8.9172e-09, 1.0691e-08, 1.1723e-08, 9.3017e-08,\n",
            "         5.2206e-08, 2.0601e-08, 7.0214e-08, 2.3189e-08, 4.9516e-08, 1.0445e-07,\n",
            "         1.1103e-08, 6.6609e-09, 2.9225e-08, 1.2018e-08, 8.1543e-09, 1.1946e-08,\n",
            "         1.6137e-08, 1.1898e-08, 1.1084e-08, 1.3053e-08, 6.0086e-09, 8.5662e-09,\n",
            "         6.7687e-09, 8.0143e-09, 2.1293e-08, 8.9048e-09, 9.6759e-09, 1.1495e-08,\n",
            "         1.0305e-08, 1.0659e-08, 8.7636e-09, 7.6880e-09, 9.3954e-09, 7.6396e-09,\n",
            "         1.0741e-08, 1.2890e-08, 1.1815e-08, 2.1149e-08, 8.4827e-09, 9.4377e-09,\n",
            "         5.4333e-08, 1.3746e-08, 1.1915e-08, 1.8921e-08, 1.2590e-08, 5.3263e-09,\n",
            "         9.3294e-09, 1.0391e-08, 1.1803e-08, 1.8700e-08, 1.1717e-08, 1.1228e-08,\n",
            "         8.1052e-09]])\n",
            "Sum of probes are= 0.9999999403953552\n",
            "Input==========من\n",
            "probes= tensor([[3.5472e-01, 4.8512e-04, 4.4127e-07, 3.1251e-08, 7.4342e-08, 1.4844e-05,\n",
            "         1.6725e-05, 1.6723e-02, 1.9370e-03, 3.5199e-02, 1.0733e-04, 1.4539e-03,\n",
            "         2.5967e-04, 2.7673e-04, 5.2878e-03, 4.3384e-04, 1.2598e-01, 4.1599e-03,\n",
            "         2.4402e-02, 1.5789e-03, 1.1160e-05, 1.5737e-04, 1.6723e-03, 1.6156e-04,\n",
            "         1.2013e-02, 7.8984e-05, 2.5184e-02, 6.2898e-02, 1.5776e-01, 2.9102e-02,\n",
            "         2.9423e-02, 1.1427e-03, 2.7237e-03, 1.2482e-02, 8.0034e-04, 5.3252e-02,\n",
            "         6.6228e-04, 3.1902e-05, 1.7311e-03, 7.4467e-04, 2.3361e-05, 2.0742e-05,\n",
            "         5.2531e-05, 7.4260e-03, 1.9452e-02, 1.7664e-08, 2.0647e-08, 1.1050e-08,\n",
            "         3.9966e-08, 1.0069e-08, 1.9695e-08, 9.8923e-09, 1.4548e-04, 1.4481e-08,\n",
            "         1.2476e-08, 1.5074e-08, 7.7395e-09, 1.5921e-08, 7.1286e-03, 6.4972e-09,\n",
            "         1.1685e-08, 1.9966e-08, 1.5498e-08, 8.7119e-09, 1.4721e-08, 1.3879e-08,\n",
            "         8.3091e-09, 9.8566e-09, 2.0857e-08, 1.5092e-08, 1.6270e-08, 7.6450e-09,\n",
            "         2.0425e-08, 6.3670e-07, 1.2895e-08, 2.3667e-08, 1.3357e-08, 1.6635e-08,\n",
            "         2.9317e-08, 1.6008e-08, 1.5814e-08, 1.7946e-08, 1.4250e-08, 1.3871e-08,\n",
            "         6.8757e-09, 6.9414e-09, 4.9920e-09, 2.8243e-06, 1.1978e-08, 1.3020e-08,\n",
            "         3.2335e-08, 1.4401e-08, 1.1265e-08, 1.1157e-08, 1.4099e-08, 1.0038e-08,\n",
            "         1.2946e-08, 1.5531e-07, 1.3562e-08, 1.4698e-08, 1.0851e-08, 1.2152e-08,\n",
            "         2.7881e-08, 1.1090e-07, 1.5451e-08, 3.2811e-08, 1.8428e-08, 2.7792e-08,\n",
            "         9.2654e-07, 7.0602e-07, 5.0956e-05, 2.6496e-09, 2.4838e-06, 2.9671e-05,\n",
            "         1.6554e-06, 4.3610e-05, 1.6359e-07, 1.8817e-08, 2.4098e-06, 6.2618e-05,\n",
            "         7.2808e-06, 2.1081e-06, 1.3644e-06, 6.3653e-07, 4.8563e-07, 6.2233e-07,\n",
            "         3.8332e-06, 2.2608e-06, 3.8637e-06, 1.1451e-05, 3.4786e-06, 1.3608e-06,\n",
            "         1.6487e-05, 2.1926e-05, 6.5471e-08, 7.1704e-07, 2.2517e-08, 1.2905e-08,\n",
            "         1.4798e-08, 2.0013e-08, 8.8554e-05, 5.8650e-07, 1.4460e-08, 1.2734e-08,\n",
            "         2.0089e-07, 7.1893e-06, 3.4099e-07, 3.9549e-06, 3.7325e-05, 2.4937e-05,\n",
            "         2.3098e-08, 7.3716e-08, 1.0215e-08, 5.9306e-07, 1.2729e-06, 8.1728e-08,\n",
            "         1.2147e-06, 1.1519e-08, 1.6177e-05, 2.4107e-06, 2.2151e-08, 2.0809e-08,\n",
            "         9.5942e-08, 1.1726e-08, 1.1943e-08, 4.1559e-06, 1.1306e-08, 7.4885e-09,\n",
            "         6.4555e-07, 6.7195e-07, 1.7112e-07, 2.9766e-08, 8.4027e-09, 2.5941e-06,\n",
            "         5.0554e-06, 4.1080e-05, 5.6285e-06, 1.8095e-06, 5.5744e-06, 1.0264e-06,\n",
            "         1.2422e-08, 1.1601e-07, 1.3978e-08, 9.4603e-09, 3.6286e-07, 7.2818e-08,\n",
            "         1.0121e-08, 1.2469e-08, 3.5361e-07, 3.4596e-05, 1.0287e-06, 3.8034e-07,\n",
            "         1.9497e-06, 1.5906e-08, 4.3441e-05, 2.2128e-05, 7.4615e-06, 1.3537e-08,\n",
            "         2.8200e-07, 1.2793e-06, 1.5136e-08, 1.1479e-08, 3.9275e-07, 1.1956e-06,\n",
            "         1.1241e-05, 1.8862e-05, 2.5025e-06, 3.1681e-06, 2.4769e-06, 2.0305e-08,\n",
            "         1.1217e-08, 2.8837e-08, 9.2550e-09, 4.4859e-07, 1.2868e-08, 1.3795e-08,\n",
            "         1.3489e-08, 1.7546e-07, 1.5751e-08, 2.9991e-08, 1.3043e-08, 2.0317e-08,\n",
            "         9.2721e-09, 1.2091e-07, 1.1692e-08, 1.3839e-08, 1.2479e-08, 2.9142e-07,\n",
            "         2.3033e-07, 2.8427e-08, 4.5773e-07, 2.5592e-08, 1.0144e-06, 2.6154e-07,\n",
            "         1.6017e-08, 7.7682e-09, 4.7982e-08, 1.3505e-08, 9.3410e-09, 1.1335e-08,\n",
            "         1.7430e-08, 1.8252e-08, 1.3967e-08, 2.1573e-08, 8.3461e-09, 1.4591e-08,\n",
            "         8.6852e-09, 1.2246e-08, 2.2056e-08, 1.0371e-08, 1.8432e-08, 2.0081e-08,\n",
            "         1.1417e-08, 1.5471e-08, 1.1155e-08, 1.0993e-08, 1.0184e-08, 9.3472e-09,\n",
            "         1.1384e-08, 1.2674e-08, 1.6139e-08, 3.0500e-08, 1.2432e-08, 1.1469e-08,\n",
            "         3.0994e-07, 1.5403e-08, 1.5352e-08, 1.9883e-08, 9.6358e-09, 5.8541e-09,\n",
            "         8.4275e-09, 1.9876e-08, 1.5056e-08, 1.9814e-08, 1.4643e-08, 1.1752e-08,\n",
            "         1.1428e-08]])\n",
            "Sum of probes are= 1.0\n",
            "Input==========شهر\n",
            "probes= tensor([[5.0351e-01, 2.0423e-04, 6.3433e-09, 3.4336e-09, 4.2396e-09, 9.7955e-05,\n",
            "         6.8232e-05, 4.5362e-02, 3.3809e-03, 3.4897e-02, 3.3373e-06, 2.0268e-04,\n",
            "         1.4125e-04, 1.8630e-03, 1.4391e-02, 4.7348e-05, 3.1514e-03, 6.8551e-04,\n",
            "         1.4724e-03, 3.3675e-03, 1.7019e-05, 1.0113e-04, 4.9783e-04, 2.6093e-04,\n",
            "         2.9845e-03, 2.7508e-04, 7.8663e-04, 2.2003e-02, 7.8515e-02, 4.8711e-02,\n",
            "         5.3298e-02, 1.2567e-03, 4.8525e-04, 4.9288e-03, 4.9815e-03, 1.3140e-01,\n",
            "         2.7121e-05, 4.6330e-05, 8.3858e-05, 5.4547e-04, 1.0876e-05, 1.2005e-05,\n",
            "         3.8684e-06, 1.3357e-03, 2.8882e-02, 3.2568e-09, 5.3095e-09, 2.1042e-09,\n",
            "         5.3129e-09, 2.0965e-09, 3.1120e-09, 2.8054e-09, 2.2742e-06, 3.1948e-09,\n",
            "         2.6904e-09, 3.3184e-09, 1.6657e-09, 3.9192e-09, 5.6930e-03, 1.5772e-09,\n",
            "         3.0928e-09, 3.2934e-09, 3.5974e-09, 1.3779e-09, 3.2290e-09, 2.6913e-09,\n",
            "         1.8027e-09, 2.2873e-09, 2.5995e-09, 2.9566e-09, 2.8879e-09, 1.7052e-09,\n",
            "         5.0160e-09, 1.7964e-07, 2.3278e-09, 5.2541e-09, 2.5700e-09, 3.9115e-09,\n",
            "         4.6555e-09, 3.3058e-09, 3.3894e-09, 2.8061e-09, 3.4071e-09, 2.3763e-09,\n",
            "         2.0873e-09, 1.7538e-09, 1.2180e-09, 3.8603e-06, 1.9913e-09, 2.6701e-09,\n",
            "         6.6886e-09, 2.1560e-09, 2.0712e-09, 1.9727e-09, 2.5728e-09, 2.2548e-09,\n",
            "         2.3629e-09, 4.7055e-08, 2.4810e-09, 2.6624e-09, 2.0547e-09, 2.8061e-09,\n",
            "         5.2963e-09, 1.1947e-08, 2.6409e-09, 5.0331e-09, 6.3971e-09, 1.6278e-08,\n",
            "         1.5263e-08, 3.3594e-10, 7.5353e-09, 1.4623e-09, 1.3960e-08, 3.5113e-08,\n",
            "         5.8579e-08, 1.4534e-08, 3.7330e-08, 4.2515e-09, 2.9065e-08, 6.2096e-09,\n",
            "         5.0973e-08, 2.8749e-08, 3.5087e-08, 7.2213e-09, 1.2440e-08, 4.6298e-08,\n",
            "         2.6887e-08, 3.5105e-09, 1.7112e-07, 2.1582e-08, 1.7223e-08, 2.8239e-09,\n",
            "         7.4874e-09, 2.3198e-09, 6.0274e-09, 1.8758e-08, 4.3531e-09, 2.5266e-09,\n",
            "         1.7538e-09, 4.3709e-09, 3.1072e-08, 1.8294e-08, 2.4857e-09, 2.7190e-09,\n",
            "         2.0436e-08, 2.8315e-08, 2.8863e-08, 2.6720e-08, 3.3180e-08, 2.5841e-08,\n",
            "         4.5798e-09, 9.0697e-09, 1.9849e-09, 1.8729e-08, 9.0770e-08, 6.9111e-09,\n",
            "         1.9281e-08, 2.0691e-09, 6.6146e-08, 1.9393e-08, 5.2678e-09, 4.0083e-09,\n",
            "         9.7704e-09, 2.8176e-09, 2.9134e-09, 3.8529e-08, 2.1899e-09, 2.0100e-09,\n",
            "         2.6642e-08, 7.8174e-09, 1.2232e-08, 6.1595e-09, 2.3728e-09, 4.5811e-08,\n",
            "         8.9126e-09, 2.9749e-08, 4.7152e-09, 1.2742e-07, 2.3669e-08, 2.7409e-08,\n",
            "         1.9510e-09, 4.6604e-08, 2.3367e-09, 1.8874e-09, 2.4768e-09, 6.5446e-09,\n",
            "         2.3654e-09, 2.7599e-09, 2.2876e-08, 6.1916e-08, 2.7009e-09, 2.9452e-08,\n",
            "         4.2464e-08, 3.5138e-09, 1.0504e-07, 2.4146e-08, 3.3499e-08, 3.2876e-09,\n",
            "         1.9855e-08, 2.4755e-08, 2.6185e-09, 2.7300e-09, 2.1219e-08, 3.7821e-08,\n",
            "         4.7600e-08, 5.3133e-08, 8.0692e-09, 2.6000e-08, 4.4214e-08, 3.0455e-09,\n",
            "         2.6558e-09, 4.8956e-09, 2.6602e-09, 2.3517e-08, 2.7413e-09, 2.5290e-09,\n",
            "         3.3731e-09, 1.3728e-08, 4.9722e-09, 6.1826e-09, 2.0161e-09, 3.3892e-09,\n",
            "         2.2660e-09, 1.2432e-08, 2.4983e-09, 2.8552e-09, 2.7575e-09, 3.4921e-08,\n",
            "         1.6729e-08, 4.8648e-09, 2.4921e-08, 5.4573e-09, 1.5209e-08, 2.8234e-08,\n",
            "         2.7753e-09, 2.0626e-09, 8.5414e-09, 2.3295e-09, 2.0077e-09, 2.6980e-09,\n",
            "         3.5420e-09, 3.4035e-09, 3.1265e-09, 3.7872e-09, 1.5721e-09, 2.4486e-09,\n",
            "         1.4070e-09, 1.9191e-09, 5.6334e-09, 2.5362e-09, 2.8785e-09, 3.2709e-09,\n",
            "         2.5766e-09, 2.6880e-09, 2.3066e-09, 2.1290e-09, 2.5458e-09, 1.6230e-09,\n",
            "         2.1973e-09, 3.1245e-09, 3.3932e-09, 6.1678e-09, 2.4325e-09, 2.7167e-09,\n",
            "         1.9162e-08, 3.6536e-09, 3.4206e-09, 5.2346e-09, 3.1410e-09, 1.3531e-09,\n",
            "         2.0830e-09, 2.4686e-09, 3.2299e-09, 4.6706e-09, 3.4942e-09, 2.5742e-09,\n",
            "         2.6747e-09]])\n",
            "Sum of probes are= 1.000000238418579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:132: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wEeSCEPVvxG",
        "outputId": "80dfe574-9b12-4405-8f01-2c2943440e43"
      },
      "source": [
        "_input = \"انتخا\"\n",
        "prob , outout = util.get_next_char(_input)\n",
        "print(f\"Input=========={_input}\")\n",
        "print(\"probe=\",prob,'\\n', \"Char=\", outout )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input==========انتخا\n",
            "probe= ن \n",
            " Char= 0.8138872981071472\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35BqQoEiYLFJ",
        "outputId": "bfe604da-afe7-4f69-8337-d5d24fe6b10d"
      },
      "source": [
        "_input = \"انتخا\"\n",
        "output = util.generate_text(_input, 100)\n",
        "print(f\"Input=========={_input}\")\n",
        "print(\"probe=\",prob,'\\n', \"Char=\", output )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input==========انتخا\n",
            "probe= ن \n",
            " Char= انتخان به این مورد است که در این روز است که در این مورد است و از این موانع است و این موانع است و این مورد\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bymdYJbmZwgD",
        "outputId": "49ac8999-69b4-4d4c-89b4-4423e973587a"
      },
      "source": [
        "_input = \"یاد\"\n",
        "output = util.generate_text(_input, 1000)\n",
        "print(f\"Input=========={_input}\")\n",
        "print(\"probe=\",prob,'\\n', \"Char=\", output )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input==========یاد\n",
            "probe= ن \n",
            " Char= یاد از این مواطق است که در این مواده این مواد می شود و به این مواد می شود از این مورد این مواد می شود و این مواد می شود و به این مواده از این بازی از این است که در این موانع این مورد است و این مواد می شود و از این مواد می شود و به این مواد می شود و از این مواد می شود و در این مواطق است که در این موضوع است که از این مورد است که در این موار می شود و در این موانقات است که در این موانع است که از این موضوع است که این موان است که در این موار می شود و این مواده از این موار می شود و این مواد می شود و در این مرابقه است اما این مواد دارد و است که در این مواد می شود و این مواد می شود و به این مورد این مواده است و از این مواد می شود این موانع است که این مورد است که در این مواد می شود این مورد این مواد داد و از این مواد می شود و این مورد این موران است که در این مواد می شود و از این مواد کرد و این مرابقه است که در این مواد می شود و از این مواده از این مواد مراور است که این مواد است و این مواد می شود و این مواطق است و از این مواد مراوره است که در این مورد است و این موانع است که در این موابع است که در ای\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-SXjvIXaHFu",
        "outputId": "c0a67a12-6cab-40eb-fdda-df58cf8a91e1"
      },
      "source": [
        "_input = \"مقد\"\n",
        "output = util.generate_text(_input, 200)\n",
        "print(f\"Input=========={_input}\")\n",
        "print(\"probe=\",prob,'\\n', \"Char=\", output )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input==========مقد\n",
            "probe= ن \n",
            " Char= مقد از این مواد می شود و این مواد می شود و این امتخابات است و در این مورد این مواد می شود و این مورد است که این مورد این مورد این مواده از این مواده است و از این مواد می شود و این موانقت و به این مواده ا\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMZ6b2h6ba_P",
        "outputId": "04d96438-d751-4337-b1fd-8720426306b1"
      },
      "source": [
        "_input = \"من محمد مقدس هستم\"\n",
        "output = util.get_overall_prob(_input)\n",
        "print(f\"Input=========={_input}\")\n",
        "print(\"probe=\",output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input==========من محمد مقدس هستم\n",
            "probe= -58.14199971017963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:132: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjjPEEKacEI_",
        "outputId": "698cd99f-6dfe-455e-8895-5650b9551767"
      },
      "source": [
        "_input = \"ییی یییی ییی ییییی\"\n",
        "output = util.get_overall_prob(_input)\n",
        "print(f\"Input=========={_input}\")\n",
        "print(\"probe=\",output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input==========ییی یییی ییی ییییی\n",
            "probe= -58.53320055751033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:132: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NORCaQ25dRVc"
      },
      "source": [
        "test_data = pd.read_csv(\"./test.csv\",sep=\"\\t\", error_bad_lines= False , encoding= 'utf-8')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji-FfIXdc7WB",
        "outputId": "b42ea12e-399e-4eb6-8075-80a501846ae7"
      },
      "source": [
        "test_pre = Preprocessor(test_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total characters = 26599835\n",
            "\n",
            "Unique characters = 206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "2ik1TPrNdcxS",
        "outputId": "dc1ed91b-bd76-460a-8791-8378bc069466"
      },
      "source": [
        "_input = test_pre.cleaned_list\n",
        "for sample in _input:\n",
        "  tokens = sample.split()\n",
        "  output = util.evaluate(' '.join(tokens[:7]), sample)\n",
        "  print(f\"Test sample=========={sample}\")\n",
        "  print(\"probe=\",output)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test sample==========\\s به گزارشحوزه ادبیات باشگاه خبرنگاران این کتاب شامل عکس های هوایی از مناظر ایران با شعرهایی از مولف که دل نوشته های وی روی تصاویر است به دو زبان فارسی و انگلیسی طراحی و به چاپ این کتاب در قطع خشتی و N صفحه تمام رنگی با تیراژ N عدد توسط نشر تحریر خیال منتشر شده و در اختیار علاقمندان قرار ویژگی عکس های هوایی این کتاب انتزاعی بودن تاکید بر فرم و جزئیات تصاویر می باشد که کمتر در عکس های هوایی عکاسان ایرانی یونس کلاهدوز استاد خلبانی است که زیادی را برای ثبت این لحظه ها تلاش نموده و در مقدمهکتاب چشم آسمان می نویسد این کتاب نگاهی است از آسمان به زمین و زندگی فارغ از قواعد معمول عکاسی با توجه به جزئیات تصاویر برخلاف آنچه در عکس های هوایی ایران رایج است این کتاب عکس نوشته هایی است در لحظه های منحصر بفرد و شوق انتقال این احساس و نگاه به مخاطبان می باشد لازم به ذکر است پیش از این عکاس سوئیسی به نام گئورگ گریستر با شباهتهایی به لحاظ سبک عکاسی ایران از آسمان به تصویر که نمایشگاهی را نیز با عنوان بهشت گمشده بر فراز ایران را به نمایش درآورد قیمت پشت جلد این کتاب N هزار تومان است انتهای \\e\n",
            "probe= 199.77621873146725\n",
            "Test sample==========\\s محمدعلي محمدي سراينده نخستين شعر دفاع مقدس در گفتگو با خبرنگار بخش ادب باشگاه خبرنگاران با اشاره به تاثير فاكتور انحراف معيارها در شكل گيري مشكلات حوزه هنري افزود برخلاف ادعاي محسن مومني مدير كنوني حوزه هنري مبني بر تاثير كمبود بودجه در شكل گيري مشكلات حوزه هنري مشكلات اين حوزه برپايه انحراف معيارها استوار وي در ادامه با برشماري اهداف اوليه حوزه هنري گفت اين حوزه كه در اولين مراحل تاسيس خود هدفي جز تربيت هنرمند نداشته هم اكنون تبديل به مركزي براي ارائه خدمات هنري اين شاعر در پايان خاطرنشان كرد من اين سه مدير اسبق و فعلي حوزه هنري را به مناظره دعوت مي كنم لازم به ذكر است محمدعلي محمدي در حال حاضر گزارشي با عنوان كمين واژه ها را با موضوع تاريخچه تاسيس پايگاه جنگهاي الكترونيك سپاه براي چاپ و انتشار در اختيار حوزه هنري قرار داده و معتقد به ارائه اين كتاب N صفحه اي در بيست و پنجمين نمايشگاه بين المللي كتاب تهران است \\e\n",
            "probe= 50.225780629393206\n",
            "Test sample==========\\s مهدی مدیر گروه فیلم و سریال شبکه پنج در خصوص آماده پخش و در حال نگارش این شبکه در گفتگو با رادیو خبرنگاران یک زن به کارگردانی مسعود کرامتی و اسماعیل عفیفه آماده پخش بوده که عید فطر به روی آنتن شبکه پنج یک زن N قسمتی است و داستان زنی بنام شیوا که اتفاقات زندگی خودش و اطرافیانش را در آن را بیان از یاد رفته عنوان سریال دیگری است که برای ایام محرم در نظر این کار را اکبر تحویلیان برعهده داشته و این مجموعه همچنین در مرحله نگارش است از یاد رفته را حامد افضلی و سارا بر عهده دارند وی افزود دیگری که در مرحله نگارش بوده و برای پخش در شبکه پنج مدنظر قرار گرفته در جستجوی آرامش است که آنرا علی و نویسندگی آن را نیلوفر محلوجیان نرگس الهی و محمد طاهری بر عهده دارند و در نهایت مجموعه گرانباری به کارگردانی و نویسندگی احسان که این کار نیز در حال نگارش است اظهار داشت سه سریال در مرحله نگارش به سر برده و هنوز عوامل سازنده آن و زمان پخش آنها مشخص نیست \\e\n",
            "probe= 127.97407134615862\n",
            "Test sample==========\\s به گزارش حوزه سینما باشگاه خبرنگاران به نقل از روابط عمومی سیزدهمین جشنواره فیلم مقاومت اسامی مستند بخش مسابقه این دوره از جشنواره به شرح زیر و شامل N فیلم وقتی آنها آمدند به کارگردانی زهره یزدان پناه قره تپه به پشت تابلو نگاه کن به کارگردانی محسن برمهانی داستان یک شهر به کارگردانی فرشید آذری لبیک به کارگردانی وحید امیرخانی عملیات آسمان به کارگردانی جواد توانا بهار شیراز به کارگردانی محمد داودی فیلم نا تمامی برای دخترم سمیه به کارگردانی مرتضی پایه شناس به کارگردانی الهام حسامی چشم ها به کارگردانی محمد فرطوسی دنیای قشنگ نو به کارگردانی کوروش سلیم زاده ابرها در راهند به کارگردانی محمدعلی فارسی بابا آمد به کارگردانی سیامک مختاری یاسمن به کارگردانی محمد علی فارسی اسلام هراسی در اروپا به کارگردانی احمد علی زاده دون و پرفسور به کارگردانی علیرضا اسلامی یرموک بهانه ای برای آزادی به کارگردانی سید محسن اصغر زاده ام غیاث به کارگردانی مجید ذوالفقاری مدافعان نبل و الزهرا به کارگردانی طه فروتن درس های یک جنگ پست مدرن به کارگردانی محمدرضا ابوالحسنی آقای ژنرال به کارگردانی احسان اصغرزاده مثل عطر بابونه ها به کارگردانی حسن ساجدی خاطراتی برای تمام فصول به کارگردانی مصطفی رزاق کریمی تولد در زمین سوخته به کارگردانی وحید فرجی اتاق جنگ به کارگردانی مصطفی حریری ننه قربون به کارگردانی یاسر عرب مالکیه به کارگردانی محمدباقر شاهین ملی بدون کارت به کارگردانی محمدعلی شعبانی مادران سرزمین جنگ به کارگردانی سلمان حسین قاسمی مستند خالد و مجتبی به کارگردانی روح الله رفیعی خط اغتشاش به کار گردانی جلال کوه دره ای سازمانی برای جدایی به کارگردانی ایمان گودرزی آخرین روزهای زمستان به کارگردانی محمد حسین مهدویان اوباما به کارگردانی محمدصادق باطنی آخرین پادگان به کارگردانی امیر تاجیک به نام من نه به کارگردانی امیر تاجیک ارتباط اسرائیلی به کارگردانی امیر تاجیک جنگ اطلاعاتی به علی نظری صبح روز بعد به کارگردانی امیر تاجیک رنگ آب به کارگردانی امیر تاجیک ثروت سرقت رفته به کارگردانی احمد بهاء الدین سید صالح آن به کارگردانی جعفری سعادتمند آنسوی ارس عبرت به کارگردانی مهدی صفری بحرین به کارگردانی فاطمه موسوی آقا سید به کارگردانی سید روح الله رفیعی بیداری عکاس به کارگردانی محمدحسین زینلی لبخند در رگهای غیرت به کارگردانی محمد رسولی فرزند حبیب اله به کارگردانی سیدرضا حسینی گاو خشمگین به کارگردانی مهدی نقویان انتهای اس \\e\n",
            "probe= 110.14509838576087\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-8d32331a53eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test sample=========={sample}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"probe=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-112612107867>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, prefix, target)\u001b[0m\n\u001b[1;32m    176\u001b[0m           \u001b[0;31m# Forward propagate RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m           \u001b[0;31m# print(input.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m           \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m           \u001b[0;31m# Sample a word id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-84b7e43afaef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# print(linear.shape,\"*********\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 680\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy0DEezggUkx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}